[
  {
    "title": "Building a Visual, Drag-and-Drop ERP for Small-Med.md",
    "content": "## Building a Visual, Drag-and-Drop ERP for Small-Medium Enterprises: Comprehensive Suggestions and Ideas\n\nGiven your Django expertise and experience building data management systems with intelligent interfaces, creating a visual ERP focused on SMEs is an excellent direction. Here's a comprehensive guide with suggestions and ideas tailored to your requirements.\n\n### Core Architecture Recommendations\n\n**Web-Based Self-Hosted Deployment**\n\nFor a PC-hosted solution without dedicated servers, consider a lightweight architecture using Django with SQLite or PostgreSQL. This allows businesses to run the ERP on a standard workstation without complex infrastructure. You can package it as a standalone application with built-in database management, similar to how ERPNext offers self-hosted options.\n\n**Technology Stack Based on Your Expertise**\n\nSince you're already proficient with Django, PostgreSQL, MySQL, and JavaScript, leverage:\n\n- **Backend**: Django with Django REST Framework for API endpoints\n- **Database**: PostgreSQL for robust features or SQLite for ultra-lightweight deployment\n- **Frontend**: React.js or Vue.js for interactive drag-and-drop interfaces\n- **UI Framework**: Bootstrap or Tailwind CSS for responsive, mobile-friendly design\n\nThe Django ERP Framework is an excellent starting point, offering reporting engines, chart capabilities, and widget systems.\n\n### Visual Interface and Drag-and-Drop Features\n\n**Modern UI/UX Best Practices**\n\nBased on 2025 ERP trends, focus on these visual elements:\n\n**Role-Based Dashboards**: Customizable widgets that users can drag and drop to arrange their workspace according to their needs. Each user role (manager, accountant, warehouse staff) sees only relevant information.\n\n**Visual Workflow Builder**: Implement a drag-and-drop workflow automation designer where users can create business processes visually without coding. This is crucial for SMEs that lack technical resources.\n\n**Kanban-Style Task Management**: Drag-and-drop job scheduling similar to Infor Visual ERP, where foremen can prioritize work orders by simply dragging them. This visual approach is intuitive for shop floor management.\n\n**Interactive Data Visualization**: Use charts, graphs, and real-time dashboards instead of text-heavy reports. Your experience with chart generation will be valuable here.\n\n**Drag-and-Drop Form Builder**: Allow administrators to create custom data entry forms by dragging field components, similar to your smart-import-manager work.\n\n### Essential ERP Modules for SMEs\n\nBased on research, prioritize these modules:\n\n**1. Financial Management Module**\n\n- General ledger, accounts payable/receivable\n- Automated invoice generation and billing\n- Bank reconciliation and payment processing\n- Visual cash flow forecasting dashboards\n\n**2. Inventory Management**\n\n- Real-time stock tracking with visual indicators\n- Drag-and-drop warehouse layout designer\n- Automated reorder alerts with visual thresholds\n- Barcode/QR code scanning integration (your ERP project experience)\n\n**3. Sales and CRM Module**\n\n- Lead scoring and pipeline visualization\n- Drag-and-drop deal stage management\n- Automated follow-up reminders\n- Customer portal for self-service\n\n**4. Purchase and Procurement**\n\n- Visual supplier management dashboard\n- Automated purchase order generation\n- Drag-and-drop approval workflows\n\n**5. HR and Payroll (Basic)**\n\n- Employee onboarding workflows\n- Leave request automation\n- Attendance tracking with visual calendars\n\n**6. Reporting and Analytics**\n\n- Customizable report builder with drag-and-drop fields\n- Real-time KPI dashboards\n- Export to Excel/CSV/PDF (your existing capability)\n\n### Intelligent Automation and Autofill Features\n\n**Smart Data Entry**\n\nBased on your smart-import-manager experience, implement:\n\n**Intelligent Column Mapping**: Automatically suggest field mappings when importing data, similar to your template system\n\n**Autocomplete and Suggestions**: As users type, provide smart suggestions based on historical data and patterns\n\n**Form Autofill**: Pre-populate forms using customer history, previous transactions, or templates\n\n**Duplicate Detection**: Automatically flag potential duplicate entries (customers, products) before saving\n\n**Automated Calculations**: Real-time computation of totals, taxes, discounts as users enter data\n\n**Workflow Automation Examples**:\n\n- Automatically route purchase orders for approval based on amount thresholds\n- Send notifications when inventory falls below reorder points\n- Generate invoices automatically when orders are marked complete\n- Update financial records when payments are received\n- Create recurring billing schedules without manual intervention\n\n### Self-Hosted Implementation Strategy\n\n**Installation Simplicity**\n\nMake installation as simple as possible for non-technical SME owners:\n\n1. **One-Command Setup**: Similar to Django CMS, provide a single command to initialize everything\n\n```\npython erp_install.py\n```\n\n2. **Embedded Database**: Use SQLite by default for zero-configuration deployment, with option to upgrade to PostgreSQL as business grows\n3. **Built-in Web Server**: Package with a production-ready server (Gunicorn or Waitress) so users don't need Apache/Nginx setup\n4. **Configuration Wizard**: First-time setup wizard with visual steps for company information, modules selection, and admin account creation\n5. **Portable Installation**: Allow the entire system to run from a single folder that can be copied between machines\n\n**Local Network Access**\n\nEnable multiple users on the same local network to access the ERP from their browsers:\n\n- Automatic local IP detection and network sharing\n- No cloud subscription required\n- Data stays completely on-premise for security-conscious businesses\n\n### Progressive Web App (PWA) for Offline Capability\n\nSince you're building web-based, implement PWA features for offline functionality:\n\n**Service Workers**: Cache critical application assets and data\n\n**IndexedDB Storage**: Store transaction data locally when internet is unavailable\n\n**Background Sync**: Queue operations performed offline and sync when connection returns\n\n**Offline-First Design**: Allow users to continue entering sales, inventory updates, or expenses even without connectivity\n\nThis is particularly valuable for SMEs with unreliable internet or field operations.\n\n### Modular and Scalable Architecture\n\n**Start Small, Grow Later**\n\nDesign a modular system where SMEs can:\n\n- Begin with only essential modules (accounting + inventory)\n- Add modules as they grow (CRM, manufacturing, e-commerce)\n- Pay nothing for unused features (free/open-source model)\n\nYour Django experience with multi-database management will help here—each module could potentially have its own data schema while sharing common infrastructure.\n\n### Visual Design Inspirations\n\n**Clean, Modern Interface Elements**:\n\n- **Card-Based Layouts**: Group related information in draggable cards\n- **Color-Coded Status Indicators**: Visual traffic lights for inventory levels, payment status, order progress\n- **Timeline Views**: Visualize order fulfillment, project milestones, or payment schedules\n- **Split-Screen Views**: Show related information side-by-side (order details + customer history)\n- **Contextual Actions**: Show action buttons only when relevant, reducing clutter\n- **Empty State Guidance**: Provide helpful onboarding for new sections with visual tutorials\n\n**Mobile-Responsive Design**\n\nEnsure the interface works seamlessly on tablets and smartphones for managers checking dashboards on-the-go.\n\n### Key Differentiators for SME Market\n\n**What Makes Your ERP Attractive to SMEs**:\n\n1. **Zero Licensing Costs**: Open-source or free-to-use model\n2. **No IT Department Needed**: Self-hosted but simple to maintain\n3. **Quick Implementation**: Deploy in days, not months\n4. **Visual First**: Minimal training required due to intuitive drag-and-drop interface\n5. **Bangladesh Market Focus**: Multi-language support (Bengali + English), local tax compliance\n6. **Affordable Hardware**: Runs on standard PCs, no expensive servers\n7. **Data Ownership**: Complete control over business data\n\n### Technical Implementation Roadmap\n\n**Phase 1: Core Foundation** (2-3 months)\n\n- Django backend with RESTful API\n- User authentication and role-based access control\n- Dashboard framework with widget system\n- PostgreSQL/SQLite database setup with migration tools\n- Basic financial module (GL, AP, AR)\n\n**Phase 2: Visual Interface** (2-3 months)\n\n- React/Vue.js frontend with drag-and-drop libraries (React DnD, Vue Draggable)\n- Dashboard customization interface\n- Form builder with field dragging\n- Responsive design for mobile/tablet\n- Theme system (dark/light modes, your existing work)\n\n**Phase 3: Core Modules** (3-4 months)\n\n- Inventory management with visual stock levels\n- Sales and basic CRM\n- Purchase and procurement\n- Reporting engine with chart integration\n\n**Phase 4: Automation & Intelligence** (2-3 months)\n\n- Workflow automation builder\n- Smart data import with mapping templates (your existing work)\n- Autofill and suggestion engine\n- Notification system\n\n**Phase 5: Advanced Features** (ongoing)\n\n- Manufacturing module for light assembly\n- E-commerce integration\n- Advanced analytics and forecasting\n- PWA offline capabilities\n- Multi-company support\n\n### Leveraging Your Existing Projects\n\nYour Django MIS project components can directly transfer:\n\n- **Smart Import Manager**: Reuse for bulk data imports across all modules\n- **Multi-Database Connectivity**: Allow businesses to connect multiple locations or subsidiaries\n- **Dynamic Table Creation**: Enable custom fields for different business types\n- **Theme System**: Professional appearance with minimal customization effort\n- **User Management**: Role-based permissions for different employee levels\n\n### Monetization and Sustainability\n\n**Flexible Business Model**:\n\n1. **Open-Source Core**: Free to download and use\n2. **Premium Modules**: Charge for advanced features (manufacturing, multi-company, advanced analytics)\n3. **Professional Services**: Implementation, training, customization consulting\n4. **Support Packages**: Paid support tiers for businesses needing assistance\n5. **Hosted Option**: Offer cloud-hosted version for businesses preferring SaaS\n\n### Community and Support Strategy\n\nSince you're targeting the Bangladesh/Indian SME market:\n\n- **Local Language Documentation**: Comprehensive guides in Bengali and English\n- **Video Tutorials**: Step-by-step setup and usage videos\n- **Community Forum**: User support and feature discussions\n- **WhatsApp/Telegram Support Groups**: Popular communication channels in your region\n\n### Final Recommendations\n\n**Start with MVP Focused on Visual Experience**: Build a minimal viable product with financial management, inventory, and sales modules, but make the visual drag-and-drop interface exceptional. This will be your competitive advantage.\n\n**Leverage Low-Code Principles**: Even though you're building with traditional Django, incorporate low-code concepts—visual workflow builders, drag-and-drop form designers, and configuration over coding.\n\n**Test with Real SMEs**: Partner with 2-3 small businesses in Bangladesh to pilot your system. Their feedback will be invaluable for understanding real-world needs.\n\n**Document Everything Visually**: Create visual installation guides, video tutorials, and interactive help within the application itself.\n\n**Plan for Scalability**: Design database schemas and architecture to handle growth from 5 users to 50+ users without major rewrites.\n\nYour combination of Django expertise, database management skills, and experience building intelligent data import systems positions you well to create a compelling visual ERP solution for SMEs. The key will be maintaining simplicity while providing powerful automation—exactly the balance small businesses need.\n\n# I think we need to focus on following things:\n\n1. user can customize, create forms, implement the forms functionalities without coding,\n2. can integrate with any others app, iot devices,\n3. no limitation for extension of modules and functions\n4. very interactive and informative home page.\n5. data migration from old system to new system. this is the most crucial part, users existing data may be in excel or messed up database. which need to be migrate to this erp within shortest possible time. success of this project will rely on this. the smarter and easier this will be the probability of success will increase.\n6. I want to integrate postgresql with this in a way that no additional setup will be required for db.\n7. a non technical user and crate custom module and functionalities on this erp.\n\nhow about adding these ideas?\n\nYes, these additions are extremely valuable and align perfectly with current 2025 UX, IoT, and embedded database trends. Incorporating your six new focus areas will significantly differentiate your ERP from most lightweight SME solutions. Here are detailed insights and implementation suggestions for each new idea.\n\n---\n\n### 1. No-Code Form and Functionality Builder\n\n**Key insight:** Modern no-code tools like CodeConductor, Feathery, and Webflow allow users to visually create forms, workflows, and logic without writing code.\n\n**Approach for your ERP:**\n\n- Introduce a **Visual Form Builder** where users can drag input fields, dropdowns, and tables to design forms.\n- Allow **field logic and conditional visibility** (e.g., “If Payment Type = Credit → Show Card Details”).\n- Connect forms directly to backend models—Django can auto-generate schema from form definitions using dynamic models.\n- Add **functionality scripting through visual flow** (similar to Microsoft Power Automate) where users define “When → Do” actions, e.g., “When new invoice → send email → update ledger”.\n\n**Technical stack suggestion:**\n\n- Use React with form-building libraries like `react-hook-form` and drag utilities (React Beautiful DnD).\n- Store form designs as JSON and auto-generate corresponding models/views dynamically.\n\n---\n\n### 2. IoT Device Integration\n\n**Rationale:** IoT-ERP integration creates real-time operations links between machines, inventory sensors, or environmental data.\n\n**Example use cases:**\n\n- Sensors automatically update equipment health in ERP.\n- RFID scanners send data directly to inventory transactions.\n- GPS trackers record asset movement in shipping modules.\n\n**Implementation options:**\n\n- Build a **device integration gateway** using MQTT or WebSocket for real-time event streaming.\n- Expose a **universal API endpoint** that IoT devices can post to, so third-party systems or microcontrollers can push data securely via REST or MQTT.\n\n**Libraries/Tools:**\n\n- Use `paho-mqtt` for MQTT connectivity and asynchronous Django channels for live data updates.\n\n---\n\n### 3. Unlimited Extensibility & Modular Architecture\n\n**Objective:** Users or developers can add completely new modules, entities, or workflows without changing core code.\n\n**Implementation path:**\n\n- Design the backend to load modules dynamically (like Django apps).\n- Provide a **plugin architecture** where each module has its own folder with metadata (`module.json`).\n- Modules can register new menu entries, models, or API endpoints dynamically.\n- Allow modules to be exported/imported as `.zip` or `.json` bundles for easy sharing.\n\nThis architecture makes the system “future-proof” and developer-friendly, ensuring continuous growth.\n\n---\n\n### 4. Interactive and Informative Home Dashboard\n\n**Recommendation based on ERP UX trends:** A home dashboard must reflect personalized, actionable, context-aware intelligence.\n\n**Design suggestions:**\n\n- Use a drag-and-drop dashboard layout with configurable widgets.\n- Preload intelligent widgets (Sales Trends, Top Customers, Pending Approvals, Inventory Levels).\n- Use smooth animation and real-time updates with WebSockets.\n- Include guided onboarding visuals for new users or inactive modules.\n\n**Technology stack:**\n\n- React-Grid-Layout for widget positioning.\n- D3.js or Chart.js for analytics visualization.\n- Backend: REST API endpoints for analytics data generation.\n\n---\n\n### 5. Smart, Automated Data Migration Engine\n\n**Crucial differentiator:** Most ERPs fail here — but automation will give you a major advantage.\n\n**Inspired by** automation tools like SoftMacros and migration frameworks from Infor and AccelGrid.\n\n**Recommended pipeline:**\n\n1. Detect data source (Excel, CSV, or SQL).\n2. Analyze column structure automatically using pandas profiling.\n3. Suggest optimal target fields based on pattern recognition and history.\n4. Offer user-friendly correction with drag-and-drop field mapping.\n5. Validate and audit migrations, showing “Records Imported, Duplicates, Skipped”.\n\n**Implementation details:**\n\n- Python’s pandas + fuzzy matching for column similarity detection.\n- Dynamic template saving for recurring migrations.\n- Background task management via Celery for large datasets.\n\n---\n\n### 6. Embedded PostgreSQL Integration without Manual Setup\n\n**Solution found:** You can integrate an _embedded PostgreSQL instance_ directly in your ERP installer, similar to how Data Virtuality Server and Quarkus Embedded PostgreSQL handle it.\n\n**Strategy:**\n\n- Bundle PostgreSQL binaries with your application in a subfolder.\n- Run scripts to auto-initialize the database (`embeddedpg_initdb.sh` or `.bat`) when ERP starts for the first time.\n- Use an embedded port (e.g., `54322`) to avoid conflicts.\n- All operations (start/stop/restart Postgres) are handled by your ERP’s management panel.\n\nThis approach ensures the user doesn't need to install PostgreSQL manually, maintaining your “no setup required” principle.\n\n---\n\n### 7. Non-Technical Custom Module Builder\n\n**Modern trend:** Platforms like Blaze and Twinr already allow users to build ERP-like apps visually with logic automation and database mapping.\n\n**Your implementation idea:**\n\n- Extend the form builder into a **module builder wizard.**\n- Each module consists of:\n\n1. **Entity Definition (custom table)** – user defines fields.\n2. **Form & List View Builder** – autogenerated CRUD pages.\n3. **Workflow Configurator** – define triggers and actions visually.\n4. **Permission Designer** – set user/role access control.\n\n**Bonus idea:** Use your intelligent mapping and multi-database experience to allow linking this new module’s data to existing ones without coding (drag-to-connect).\n\n---\n\n### Integration of All Features – Vision Alignment\n\nWhen combined, these six features will transform your ERP from a standard business suite into a **visual business automation platform** for SMEs — more flexible than ERPNext but simpler to use than Odoo. It will appeal to small manufacturers and retailers needing local control, automation, and customization without technical knowledge.\n\n---\n\n### Summary of Enhanced Feature Vision\n\n| Component                | Implementation Goal                                | Supporting Reference |\n| :----------------------- | :------------------------------------------------- | :------------------- |\n| No-code Form Builder     | Drag-and-drop, conditional logic, visual scripting |                      |\n| IoT Integration          | Real-time machine and sensor data                  |                      |\n| Unlimited Extensibility  | Plugin-based modular system                        |                      |\n| Smart Dashboard          | Draggable widgets, real-time insights              |                      |\n| Automated Data Migration | AI-assisted Excel/database migration               |                      |\n| Embedded PostgreSQL      | Self-contained DB without setup                    |                      |\n| No-Code Module Builder   | New modules and workflows visually                 |                      |\n\n---\n\nIncorporating these ideas doesn’t just make your ERP more powerful — it positions it as a **visual automation ERP platform** for non-technical SME owners, bridging usability, extensibility, and intelligence in one unified ecosystem.\n"
  },
  {
    "title": "erp_masterplan_v_1.md",
    "content": "# ERP Masterplan (Visual, Drag-and-Drop, Multi-Company, AI-Assisted)\n**Version:** 2.1  \n**Date:** October 27, 2025  \n**Status:** Expanded Functional + Technical Blueprint\n\n---\n\n## 1. Vision\n\nWe are developing a next-generation ERP platform that is:\n\n- **Plug-and-play** with prebuilt industry templates (Manufacturing, NGO, Trading/Distribution, Retail/POS, Services/Telco, etc.).\n- **Visually configurable** using drag-and-drop for forms, workflows, dashboards, schema, and even new modules.\n- **AI-assisted and self-evolving**, able to ingest legacy data and reshape itself (new fields, new attributes, new logic) with minimal human effort.\n- **Multi-company / multi-tenant**, supporting inter-company transactions and group consolidation.\n- **Self-hosted or LAN-hosted**, capable of running offline on a normal office PC (Windows or Linux) with optional internet exposure.\n- **Secure and auditable**, with role-based control and immutable financial trails.\n\nThe objective is not “an ERP product,” but “a business operating system” that bends to each organization without needing developers.\n\n---\n\n## 2. Core Product Philosophy\n\n1. **Pre-built best practice**  \n   When a company is created, the user selects the Nature of Business. That selection loads a full “Industry Pack” which includes:\n   - Chart of accounts / ledger groups OR fund/grant structure.\n   - Standard processes and approval flows.\n   - Pre-modeled entities (Customer, Supplier, Work Order, Grant, etc.) and their fields.\n   - Prebuilt dashboards and KPIs.\n   - Standard statutory/compliance fields.\n   - Default reports.\n   The company starts on Day 1 with a usable ERP “template,” not a blank database.\n\n2. **Self-evolving model**  \n   The ERP data model is metadata-driven. Admins can add new fields, relationships, and even whole custom entities visually. These updates:\n   - Are stored in metadata.\n   - Update the database storage layer.\n   - Instantly appear in forms, workflows, dashboards, reporting, and AI.\n\n3. **Schema adapts to legacy data**  \n   During migration, if uploaded data has columns the ERP doesn’t have yet, the system can propose creating those new fields automatically and attaching them to the right entity. No developer required.\n\n4. **No-code control of processes**  \n   Business admins (not engineers) can:\n   - Add approval logic.\n   - Add workflow steps.\n   - Add automation triggers.\n   - Add dashboard KPIs.\n   - Add brand-new modules.\n\n5. **AI is embedded in the workflow**  \n   AI is visible as a “side panel” in every screen, not a separate chatbot. It understands current context (record, module, user role) and can answer, explain, warn, and suggest.\n\n6. **Low-friction deployment**  \n   The system is designed to run on commodity hardware in a small office, serve users over LAN, work offline (PWA), and keep data under the customer’s control.\n\n---\n\n## 3. Top-Level Objectives\n\n- Be usable by an SME without a dedicated IT department.\n- Migrate historical data fast, without painful cleanup.\n- Allow deep customization without code.\n- Enforce finance/audit integrity even when the model changes.\n- Scale from a single company to a multi-company group with inter-company flows.\n- Keep ownership of data local and private.\n- Use AI in a way that’s helpful, permission-aware, and cost-controlled.\n\n---\n\n## 4. System Architecture Overview\n\n### 4.1 Multi-Company / Multi-Tenant Core\n\n**Business behavior**\n- One installation can host multiple companies/tenants.\n- Each company has its own:\n  - Base currency, fiscal year, tax/VAT rules.\n  - Chart of accounts (or donor fund tree if NGO).\n  - Workflows and approval chains.\n  - Dashboards and KPIs.\n- Inter-company transactions:\n  - Company A raises a sales invoice to Company B.\n  - Company B automatically gets a purchase entry.\n- Consolidation:\n  - Group-level reporting (P&L, balance sheet, cash flow) across companies.\n\n**Technical**\n- `company_id` scoping on all transactional tables by default.\n- Optional per-company schema or DB for high isolation.\n- Consolidation logic queries across companies and applies elimination rules.\n- Role/permission layer includes which companies a user can access.\n\n---\n\n### 4.2 Industry Packs ("Nature of Business")\n\n**Business behavior**\n- On company creation, user picks the industry profile:\n  - Manufacturing / Garments / Factory\n  - NGO / Donor-funded org\n  - Trading & Distribution / FMCG\n  - Services / Telco / SLA-driven\n  - Retail / POS\n- The selected Industry Pack loads:\n  - Predefined entities and relationships.\n  - Predefined workflows (e.g. Requisition→PO→GRN→Bill→Payment).\n  - Predefined dashboards.\n  - Predefined approval roles.\n  - Predefined standard reports.\n  - Predefined chart of accounts or fund/grant structure.\n\n**Technical**\n- Industry Packs are versioned bundles of metadata + starter data.\n- Each pack contains:\n  - Entity definitions (fields, data types, validation rules, relationships, cardinality, visibility).\n  - Workflow definitions (graph of steps, conditions, routing rules).\n  - Dashboard definitions (widgets, queries, layouts).\n  - Permission templates (roles, default access rules).\n- Applying an Industry Pack = seeding metadata tables and base records for that company.\n- Packs can evolve. New versions of a pack can diff/merge into an existing tenant (with admin approval).\n- Packs can be extended: the company's admin can add new fields to any packed entity. Those extensions are stored as tenant-level overrides.\n\n---\n\n### 4.3 Metadata-Driven Schema Layer\n\n**Business behavior**\n- Every “thing” the ERP tracks (Customer, Item, Invoice Header, Invoice Line, Supplier, Work Order, Grant, Asset, etc.) is modeled as an **Entity**.\n- An Entity has:\n  - Fields (with labels, types, validation, allowed values)\n  - Relationships to other Entities\n  - Security/visibility flags\n  - Audit classification (financially sensitive? HR sensitive? etc.)\n\n**Technical**\n- Metadata tables define:\n  - `entity_definition`\n  - `field_definition`\n  - `relationship_definition`\n  - `workflow_definition`\n  - `dashboard_definition`\n- UI builders, workflow engine, report builder, AI assistant, and APIs all read from this metadata at runtime.\n- When a new field is added:\n  - Metadata entry is created.\n  - Physical layer is updated (see 4.5).\n  - Auto-generated forms and CRUD endpoints are updated.\n  - Report Builder and Dashboard Builder see the new field automatically.\n\n---\n\n### 4.4 Visual Schema Designer\n\n**Business behavior**\n- Admins see a diagram of all entities, with their fields and how they connect.\n- Clicking an entity opens:\n  - Field list (name, label, type, required, default, dropdown options, visibility in forms/grids/exports/AI).\n  - Relationships (to other entities, with cardinality).\n- Admins can:\n  - Add fields.\n  - Mark fields required/optional.\n  - Attach those fields to forms and workflows.\n  - Add relationships with defined cardinality and cascade.\n\n**Technical**\n- The diagram is a live view of metadata.\n- Editing the diagram updates metadata.\n- A schema reconciliation service:\n  - Applies ALTER TABLE (for promoted fields), or\n  - Adds JSONB keys (for flexible fields), or\n  - Updates relationship metadata and foreign key constraints.\n- Changes are versioned and audited.\n\n---\n\n### 4.5 Physical Storage Strategy\n\n**Business behavior**\n- The ERP must accept new fields immediately (during migration or during normal use) without waiting for a developer.\n\n**Technical model**\n- Hybrid storage:\n  - **Core columns:** Stable, high-use, compliance-critical data is stored as normal columns with indexes.\n  - **Flexible extension:** New or rarely-used fields are initially stored under `extra_data` (JSONB or similar) per record.\n  - **Promotion path:** Admin can later "Promote to First-Class Field" which:\n    - Creates a physical column.\n    - Backfills from JSONB.\n    - Adds indexing.\n- Reporting / dashboards can query both physical columns and JSONB fields.\n- Performance tuning can focus on promoted columns.\n\n---\n\n### 4.6 Workflow & Event Bus Layer\n\n**Business behavior**\n- Workflows describe how documents move: e.g. Purchase Requisition → Approval → Purchase Order → GRN → Bill → Payment.\n- Rules like "If PO > $5,000 require CFO approval" are configurable.\n- Alerts, escalations, and SLA timers can be defined.\n\n**Technical**\n- Central event bus publishes events (`Invoice.Created`, `Stock.Low`, `Timesheet.Submitted`).\n- Workflow Runtime subscribes and executes flow steps.\n- Workflow definitions are stored in metadata as graphs of nodes:\n  - Trigger nodes\n  - Condition nodes\n  - Approval nodes\n  - Action nodes (create task, send email, update record field, block next step, escalate)\n- The Workflow Runtime evaluates conditions against live entity data (including custom fields that were added later).\n- All workflow actions are audited.\n\n---\n\n### 4.7 AI Layer\n\n**Business behavior**\n- AI is a side panel available everywhere.\n- It understands the screen context: "You are viewing Sales Order #SO-0091 for Customer X".\n- It can:\n  - Explain what you're seeing.\n  - Answer questions about policy.\n  - Highlight risks (budget overrun, credit limit breach, QC hold stock, etc.).\n  - Suggest next steps ("raise PO", "schedule maintenance", "send reminder").\n\n**Technical**\n- Local LLM(s) for natural language.\n- Retrieval layer that pulls:\n  - Entity data (limited by role permissions),\n  - Policies / SOP documents,\n  - KPI history.\n- Intent parser converts user questions into queries on metadata-driven entities.\n- Role-awareness ensures AI cannot display restricted fields (salary, donor-sensitive fund balances, etc.) unless the user role can already see them directly.\n\n---\n\n### 4.8 Deployment Model / Runtime Environment\n\n**Business behavior**\n- Run on a normal office PC.\n- Serve all office users over LAN.\n- Optionally expose secure remote access.\n- Continue working during internet outages.\n\n**Technical**\n- Backend: Python/Django or FastAPI-style service layer, plus a workflow runtime and AI runtime.\n- DB: Bundled PostgreSQL with extensions (JSONB, indexing).\n- Frontend: Web app (React/Vue/Svelte style) packaged as PWA.\n- Optional GPU acceleration for AI inference.\n- Offline sync for PWA clients (queue writes, reconcile on reconnect).\n- Versioned updater with rollback and snapshot capability.\n\n---\n\n## 5. Data Migration Engine (Onboarding Layer)\n\n### 5.1 Source Ingestion\n\n**Business behavior**\n- User can upload Excel/CSV or connect to an old DB to bring in:\n  - Customers, Suppliers, Items\n  - Chart of Accounts / Donor Funds\n  - Opening Balances\n  - Stock on hand by location/bin\n  - Historical Invoices, Purchase Orders, Work Orders, Grants, etc.\n\n**Technical**\n- Every upload creates a Migration Session record.\n- Raw files are stored for audit.\n- The system profiles the data using heuristics + semantic matching.\n\n### 5.2 Profiling & Detection\n\n**Business behavior**\n- The system automatically says "This sheet looks like Customer Master" or "This looks like Invoices (header+lines).".\n\n**Technical**\n- Column name similarity, value pattern recognition, and known industry terms from the active Industry Pack.\n- Classification tries to map sheets to known Entities from the metadata.\n- It also tries to infer header/line structures where repeated values imply parent-child.\n\n### 5.3 Mapping UI\n\n**Business behavior**\n- Side-by-side mapping:\n  - Left: legacy columns (CustName, Tel, AreaCode, etc.)\n  - Right: target fields in the ERP model (Customer.name, Customer.phone, Customer.territory)\n- System auto-links most columns.\n- User can drag/drop to fix the rest.\n- Corrections are saved as a reusable import template.\n\n**Technical**\n- Mapping suggestions are stored in metadata as `import_mapping_profile` for that tenant.\n- Mapping confidence (high/medium/low) is surfaced to user.\n- Mappings can be re-used for incremental imports (monthly donor spend, daily sales, etc.).\n\n### 5.4 Schema Extension During Import\n\n**Business behavior**\n- If the legacy data has columns not present in the ERP model (e.g. `CreditRating`, `TerritoryZone`, `IMEI`, `Shade/GSM`), the system proposes adding those as new fields.\n- Admin confirms.\n- Those fields become part of the entity for this tenant.\n\n**Technical**\n- For each new column:\n  - Guess data type (text/number/date/dropdown based on unique values).\n  - Create metadata entry in `field_definition` under the right entity.\n  - Add to storage (`extra_data` initially).\n  - Update available fields in forms, reports, dashboards, workflows, and AI context.\n- This means migration actively evolves the schema.\n\n### 5.5 Cleaning & Normalization\n\n**Business behavior**\n- Before import, system proposes cleanup:\n  - Normalize date formats.\n  - Normalize currency formats.\n  - Suggest dropdowns from repeated values.\n  - Fix casing/whitespace.\n  - Attempt duplicate merge (same supplier with tiny spelling difference).\n  - Offer default fill-ins for required-but-missing fields ("PaymentTerms = NET30 for all missing?").\n\n**Technical**\n- Cleaning rules are captured and can be replayed on future imports.\n- Deduping can create merge maps ("Legacy Supplier ABC01" → "Supplier ID 118") stored for future reconciliation.\n- Address or contact splitting (FullName → first_name + last_name) can be defined as a transform step.\n\n### 5.6 Validation, Staging, Publish\n\n**Business behavior**\n- After mapping/cleaning:\n  - Validate referential integrity (invoice lines reference existing items/customers).\n  - Validate business rules (no future-dated GRN if policy forbids it).\n  - Validate regulatory rules (tax fields cannot be blank where mandatory).\n- Rows are grouped:\n  - ✅ Ready to import\n  - ⚠ Fixable with proposed defaults\n  - ❌ Blocked, with reason\n- User can import good rows now, download error sheet for the rest.\n- Imported data first lands in **staging tables**.\n- An authorized approver promotes staging → live.\n\n**Technical**\n- Staging tables mirror the metadata model.\n- Promotion to live is transactional.\n- Every row imported is tagged by Migration Session ID.\n- We log field-level before/after if we update existing records.\n\n### 5.7 Rollback & Audit\n\n**Business behavior**\n- Admin can "Undo This Import" if something is wrong.\n- Audit trail shows:\n  - Who imported.\n  - When.\n  - Source file checksum.\n  - What entities/fields were touched.\n\n**Technical**\n- Soft rollback by tracking which records were inserted/updated in that session.\n- For updated records, store pre-update snapshot for reversal.\n\n---\n\n## 6. No-Code Builders\n\nThese builders turn the platform into a self-service system for admins.\n\n### 6.1 Form Builder\n\n**Business behavior**\n- Drag-and-drop UI fields onto forms for any entity.\n- Mark fields required, read-only, hidden, conditional.\n- Add sections, tabs, repeatable line items.\n- Add inline validation (e.g. "Credit Limit cannot exceed 50000 unless role = CFO").\n\n**Technical**\n- Form layouts are metadata objects linked to entities/roles.\n- Conditional visibility and validation rules are stored as expressions referencing entity fields.\n- Versioning allows draft vs published forms.\n\n### 6.2 Custom Module Builder (Entity Builder)\n\n**Business behavior**\n- Create a brand-new entity (e.g. "Franchise Outlet Audit", "Machine Calibration Log").\n- Define fields, relationships, and permissions in a wizard.\n- Instantly get:\n  - List view\n  - Detail view\n  - Edit form\n  - API endpoints\n\n**Technical**\n- Creates new `entity_definition` and `field_definition` rows.\n- Creates DB backing (flexible storage first, columns on promotion).\n- Auto-registers endpoints, permissions, workflow hooks, and reporting availability.\n\n### 6.3 Workflow Automation Studio\n\n**Business behavior**\n- Visual flow editor with nodes:\n  - Trigger (event/time/manual)\n  - Condition (if/else on data)\n  - Approval step\n  - Action (notify, assign task, update record, block next step)\n  - Escalation (SLA breach)\n- Used for procurement approvals, credit approvals, QC gates, donor spend authorization, etc.\n\n**Technical**\n- Workflows are stored as graphs in metadata.\n- Runtime engine listens to event bus and evaluates each workflow.\n- Role-based access to approve nodes.\n\n### 6.4 Dashboard / Homepage Builder\n\n**Business behavior**\n- Drag-and-drop KPI cards, charts, tables, task lists, alerts, and AI insights onto role dashboards.\n- Each role (CFO, Store Manager, Production Manager, Donor Manager, etc.) can have a homepage.\n\n**Technical**\n- Dashboard definitions stored as metadata (`dashboard_definition`).\n- Widgets reference entity queries. Queries are built from metadata (so they can handle custom fields).\n- Access to widgets respects permissions.\n\n---\n\n## 7. Business Modules (Functional Layer)\n\nEach module:\n- Ships with defaults from the Industry Pack.\n- Can be extended (fields, workflows, dashboards) by the admin.\n- Interacts with other modules through shared entities and the event bus.\n\nFor each module below we describe:\n1. **Purpose**\n2. **Core Flow / How It Works**\n3. **Integration With Other Modules**\n4. **Technical Notes**\n\n---\n\n### 7.1 Finance & Accounting\n\n**Purpose**\n- General Ledger (GL), Accounts Payable (AP), Accounts Receivable (AR), tax/VAT, cash/bank, budgeting, and consolidation.\n\n**Core Flow**\n- All operational modules (Purchase, Sales, Payroll, etc.) post entries into Finance automatically.\n- Finance manages:\n  - Chart of Accounts (or Grant/Fund tree for NGOs).\n  - Journals and adjustments.\n  - AP (supplier bills, due dates, payments).\n  - AR (customer invoices, collections, aging).\n  - Tax/VAT calculations and returns.\n  - Closing periods.\n- Budget vs Actual is monitored per cost center.\n\n**Integration**\n- Procurement → AP.\n- Sales → AR.\n- Payroll → GL.\n- Inventory valuation → COGS postings.\n- Cost Centers and Projects link spend and revenues to budgets/donors.\n- Inter-company postings generate mirror entries in sister companies.\n\n**Technical Notes**\n- Finance entities are marked "financially critical" in metadata.\n- Certain core finance fields (amount, tax rate, posting date, ledger account) are protected: users can extend them with analytic tags (Region, DonorCode, etc.) but cannot delete/reshape them.\n- Consolidation queries run across companies, applying elimination rules.\n- Audit trail is immutable for posted journals.\n\n---\n\n### 7.2 Procurement / Purchase\n\n**Purpose**\n- Control spend from request to payment, maintain supplier relationships, enforce approvals and budgets.\n\n**Core Flow**\n1. Requisition / Purchase Request (PR).\n2. Approval workflow (conditions based on amount/category/budget availability).\n3. Purchase Order (PO) issuance to supplier.\n4. Goods Receipt Note (GRN) at warehouse.\n5. Supplier Invoice (Bill).\n6. Payment scheduling and posting to AP.\n\n**Integration**\n- Inventory module updates stock on GRN.\n- Finance/AP module gets bills and schedules payments.\n- Budget module checks if spend is within the allocated cost center budget.\n- Quality/Compliance module can inject QC hold steps before GRN is accepted.\n\n**Technical Notes**\n- Procurement workflows are metadata-defined and editable in Workflow Automation Studio.\n- Supplier master is an entity in metadata, so admins can add custom fields like ComplianceRating, LeadTimeDays, etc.\n- The event bus emits `PO.Approved`, `GRN.Received`, `Invoice.Matched`; Finance listens and posts accounting entries.\n\n---\n\n### 7.3 Inventory / Warehouse / Materials\n\n**Purpose**\n- Track quantity, location, valuation, and quality status of stock.\n\n**Core Flow**\n- Items/SKUs are defined with UoM, category, batch/lot rules, expiry.\n- Stock movements:\n  - GRN increases stock.\n  - Issue to production decreases raw materials.\n  - Production receipt creates finished goods.\n  - Sales shipment decreases finished goods.\n- Stock adjustments follow approval workflows.\n- Bin- / location-level tracking with quarantine and QC states.\n\n**Integration**\n- Procurement feeds GRN.\n- Production consumes and produces inventory.\n- Sales dispatch consumes finished goods.\n- Finance pulls valuation snapshots and posts inventory/cost-of-goods-sold.\n- Quality/Compliance module can mark lots as "on hold" or "rejected".\n\n**Technical Notes**\n- Item, Batch, Lot, Bin, StockLedger are entities in metadata.\n- Custom attributes like Shade, GSM, DyeLot, SerialNo can be attached per tenant via Visual Schema Designer or migration.\n- IoT (barcode/RFID scanners) can push stock movement events into the event bus.\n\n---\n\n### 7.4 Sales & CRM\n\n**Purpose**\n- Manage leads, quotations, orders, dispatch, invoicing, and receivables.\n\n**Core Flow**\n1. Lead / Opportunity (pipeline view).\n2. Quotation.\n3. Sales Order with credit check.\n4. Delivery / Dispatch.\n5. Sales Invoice.\n6. Collection / Receipt.\n\n**Integration**\n- Inventory is reserved/allocated for Sales Orders.\n- Finance/AR manages invoicing and collections.\n- Cost Center / Budget may track revenue targets.\n- AI can surface “credit limit exceeded” warnings from Finance.\n- Customer Service/SLA module (if service industry) can attach active service tickets and SLA status to the Customer entity.\n\n**Technical Notes**\n- Customer entity is metadata-driven: admins can add TerritoryZone, ChannelType, CreditRating fields.\n- Sales workflow (quote→order→invoice) is editable in the Workflow Automation Studio.\n- Event bus emits `SalesOrder.Confirmed`, `Invoice.Created`, etc. Finance and Inventory consume these.\n\n---\n\n### 7.5 Production / Manufacturing (Manufacturing Pack)\n\n**Purpose**\n- Plan and record production execution, material usage, and output quality.\n\n**Core Flow**\n1. Bill of Materials (BOM) defines required materials per finished good (multi-level allowed).\n2. Work Order / Production Order is opened.\n3. Materials are issued to the line.\n4. Operator/machine/line efficiency and WIP are tracked.\n5. QC checkpoints (inline, final).\n6. Finished goods are received back into Inventory.\n\n**Integration**\n- Inventory is decremented for raw material issues and incremented for finished goods.\n- Finance posts WIP and COGS.\n- Quality/Compliance records inspections and rejections.\n- Cost Center/Budget can compare planned vs actual cost.\n- Asset Management can track machine maintenance needs based on runtime.\n\n**Technical Notes**\n- BOM, WorkOrder, OperationStep, QCCheck are entities defined in metadata.\n- Admin can add fields like MachineID, NeedleType, ShadeBatch, Style/Color/Size breakdowns.\n- Event bus captures `WorkOrder.Started`, `QC.Fail`, `FG.Received` and triggers dashboards, alerts, and postings.\n\n---\n\n### 7.6 NGO / Grant / Project Accounting (NGO Pack)\n\n**Purpose**\n- Track donors, grants/funds, budget allocations, program spend, and donor reporting.\n\n**Core Flow**\n1. Donor / Grant setup with allowed cost categories.\n2. Budget allocation per program / activity / region.\n3. Expenditure is coded against grant+activity.\n4. System enforces "don’t overspend donor budget" rules and routes exceptions for approval.\n5. Generate donor-use reports (spend vs allocation, outcomes/impact KPIs).\n\n**Integration**\n- Finance posts journals but tags them with GrantID / ActivityCode.\n- Procurement and AP link bills to grant-coded cost centers.\n- HR/Payroll can allocate staff cost to grants.\n- Project Management can tie milestones and deliverables to grant reporting.\n- AI can summarize donor compliance notes from Policy documents.\n\n**Technical Notes**\n- Donor, Grant, ActivityLine, Allocation, SpendTransaction are metadata-defined entities.\n- Grant-specific budgets map into the Budget/Cost Center module.\n- Approval workflows for donor spend are managed in Workflow Automation Studio.\n\n---\n\n### 7.7 Cost Center & Budget Control\n\n**Purpose**\n- Enforce financial discipline by comparing planned budgets/targets vs actual spend/revenue.\n\n**Core Flow**\n1. Define Cost Centers or Programs (Department, Branch, Project, Grant Activity).\n2. Assign budgets and sales targets.\n3. Every spend (PR/PO/Bill) and every revenue (SO/Invoice) is tagged to a cost center.\n4. System monitors burn/achievement in real time.\n5. If over-budget or under-target risk appears, trigger escalation.\n\n**Integration**\n- Procurement checks budget availability before approving PR/PO.\n- Finance postings include cost center tags.\n- Sales pipeline shows target vs actual by zone/rep.\n- AI can warn “Budget for Marketing is 90% consumed, 2 weeks left in month.”\n\n**Technical Notes**\n- CostCenter, BudgetPlan, BudgetConsumptionSnapshot are metadata entities.\n- Workflows can block or require CFO approval if spend exceeds threshold.\n- Dashboard widgets and AI are fed by budget consumption snapshots.\n\n---\n\n### 7.8 Project & Task Management\n\n**Purpose**\n- Coordinate execution work: projects, tasks, milestones, assignments, timelines.\n\n**Core Flow**\n1. Create Project with milestones and owners.\n2. Assign tasks, due dates, dependencies.\n3. Track progress via Kanban/Gantt.\n4. Timesheets log effort, feed Payroll.\n5. Project costs and purchases tag to that project’s cost center/budget.\n\n**Integration**\n- Procurement requests can be tied to a Project.\n- Finance/budget sees spend against each Project.\n- HR/Payroll uses timesheets for cost allocation.\n- AI can flag stalled milestones or resource overload.\n\n**Technical Notes**\n- Project, Task, Milestone, Timesheet are all metadata-defined entities.\n- Relationship: Task → Assignee (Employee from HR), Task → Project.\n- Workflow automation can escalate overdue tasks.\n\n---\n\n### 7.9 HR & Payroll\n\n**Purpose**\n- Manage people, attendance, leave, payroll, and compliance.\n\n**Core Flow**\n1. Employee master data (grade, department, salary structure).\n2. Attendance capture (manual, biometric, geo-fenced mobile, etc.).\n3. Leave requests and approvals.\n4. Payroll run calculates gross/net, deductions, overtime, etc.\n5. Payslips generated and posted to Finance.\n\n**Integration**\n- Finance posts payroll journals.\n- Project Management pulls timesheets for cost allocation.\n- Asset Management can tie assets (laptop, phone) to employees.\n- Policy/Document module stores HR policies (leave, overtime rules).\n- AI can answer “What is carry-forward leave policy?” based on Policy documents.\n\n**Technical Notes**\n- Employee, AttendanceRecord, LeaveRequest, PayrollRun are metadata-defined entities.\n- Sensitive fields (salary, bank details) are permission-locked at field level.\n- Payroll posting triggers Finance with cost center splits.\n\n---\n\n### 7.10 Asset Management\n\n**Purpose**\n- Track fixed assets, their depreciation, maintenance, movement, and disposal.\n\n**Core Flow**\n1. Register asset (purchase info, cost center, custodian, location).\n2. Schedule maintenance / service.\n3. Log maintenance events.\n4. Calculate depreciation.\n5. Handle asset transfer or disposal.\n6. Post depreciation and disposal entries to Finance.\n\n**Integration**\n- Finance recognizes assets as capitalized items and books depreciation.\n- Maintenance tasks can feed Project & Task Management.\n- Production can tag downtime/failures to specific assets.\n- Quality/Compliance can log audit findings against assets.\n\n**Technical Notes**\n- Asset, MaintenanceSchedule, MaintenanceLog, DepreciationRun are metadata-defined.\n- IoT/machine runtime data can feed maintenance schedules.\n- Disposal workflow triggers Finance gain/loss postings.\n\n---\n\n### 7.11 Policy & Document Management\n\n**Purpose**\n- Centralize SOPs, HR policies, compliance guidelines, contracts, certifications.\n\n**Core Flow**\n1. Upload policy/contract/SOP with metadata (effective date, owner, expiry).\n2. Version control and approval workflow.\n3. Link policies to modules. Example: Procurement policy applies to PO approval flow.\n4. AI can read and summarize policies for end users.\n\n**Integration**\n- HR uses leave & overtime policies.\n- Quality/Compliance uses QC standards.\n- Procurement references vendor approval policy.\n- AI retrieval uses Policy documents to answer “what is allowed” questions contextually.\n\n**Technical Notes**\n- PolicyDocument entity includes version, owner, effective/expiry dates, access roles.\n- Policy can be attached to Workflow rules (block/allow actions).\n\n---\n\n### 7.12 Quality / Compliance / Audit\n\n**Purpose**\n- Enforce standards, record QC checkpoints, track nonconformances, support audits.\n\n**Core Flow**\n1. Define QC checkpoints (Incoming material, In-line, Pre-shipment).\n2. Record inspection results (pass/fail, measurements, photos).\n3. Trigger corrective action tasks if fail.\n4. Maintain compliance scorecards for suppliers.\n5. Maintain audit findings and follow-up actions.\n\n**Integration**\n- Inventory lots can be held in quarantine if QC not passed.\n- Procurement uses supplier scorecards.\n- Production captures in-line QC results.\n- Asset Management links audit findings to specific machines.\n- Policy/Document stores compliance standards.\n\n**Technical Notes**\n- QCCheck, NonconformanceReport, CorrectiveAction, AuditFinding are metadata entities.\n- Workflow Automation Studio handles corrective action routing and escalation.\n- AI can summarize recurring failure patterns.\n\n---\n\n### 7.13 Customer Service / SLA / Subscription (Service/Telco Pack)\n\n**Purpose**\n- Manage service tickets, SLAs, subscriptions/recurring billing, and field technician work.\n\n**Core Flow**\n1. Customer raises issue / ticket.\n2. Ticket is prioritized, assigned, and SLA timer starts.\n3. Technician dispatched, work logged.\n4. Resolution captured, ticket closed.\n5. Subscription billing / recurring invoice issued if applicable.\n\n**Integration**\n- Sales/CRM sees active tickets when negotiating renewals.\n- Finance handles recurring billing AR.\n- Asset Management tracks which hardware is under service.\n- AI can warn "SLA at risk" or "Churn risk" for high-complaint customers.\n\n**Technical Notes**\n- Ticket, SLAContract, SubscriptionPlan, TechnicianAssignment are metadata-defined entities.\n- Workflow Automation Studio drives escalation if SLA is about to breach.\n- Event bus emits `Ticket.Opened`, `SLA.BreachWarning`.\n\n---\n\n## 8. Industry Template Management\n\n**How templates work across different industries**\n\n1. **Template Definition**\n   - Each Industry Pack is a bundle of metadata:\n     - Standard entities and their fields.\n     - Relationships + cardinality.\n     - Default workflows.\n     - Default dashboards and KPIs.\n     - Default reports.\n     - Default permissions/roles.\n     - Chart of accounts or Donor/Fund trees.\n   - Manufacturing Pack emphasizes BOM, Work Order, QC, WIP.\n   - NGO Pack emphasizes Donor, Grant, Allocation, Spend, Compliance fields.\n   - Trading Pack emphasizes Route/Territory, Batch/Expiry, Margin per SKU.\n   - Service/Telco Pack emphasizes SLA, Ticketing, Recurring Billing.\n\n2. **Template Application**\n   - When a new company is created and chooses its Nature of Business, the platform:\n     - Seeds metadata with that Pack’s definitions.\n     - Seeds baseline dashboards.\n     - Seeds workflows (approval chains, budget checks).\n     - Seeds the finance model (CoA or Grant tree).\n   - From that point on, the company can:\n     - Extend entities (add new fields).\n     - Add new entities/modules.\n     - Edit workflows, dashboards, and roles.\n\n3. **Template Evolution**\n   - Packs are versioned. A newer version of the Manufacturing Pack can introduce improved QC workflow or new standard KPIs.\n   - The platform can show: "A newer Manufacturing template is available. Would you like to merge updates?"\n   - Merge is admin-approved and not forced.\n\n4. **Technical Storage**\n   - Packs live as exportable/importable metadata bundles.\n   - A pack bundle can be:\n     - Applied to a fresh tenant.\n     - Compared against an existing tenant to propose incremental upgrades (new dashboard widgets, new workflow steps).\n\n5. **Consistency vs Flexibility**\n   - The base Industry Pack defines a "core spine" which remains recognizable (so we can ship updates and analytics).\n   - Tenant-level extensions are layered on top. They never destroy the spine, they enrich it.\n\nThis approach lets the platform feel "industry-specific" from day one while still being infinitely adaptable per tenant.\n\n---\n\n## 9. Analytics, Reporting & Dashboards\n\n### 9.1 Report Builder\n\n**Business behavior**\n- Drag-and-drop report design:\n  - Select entities.\n  - Pick fields (including custom fields added post-go-live).\n  - Define joins using known relationships from metadata.\n  - Add filters, grouping, sorting, calculations.\n\n**Technical**\n- Report definitions are stored as metadata.\n- Query builder composes SQL under the hood using metadata (entity relationships, cardinality, promoted columns, JSONB fields).\n- Reports can be exported (Excel, CSV, PDF) or embedded as dashboard widgets.\n\n### 9.2 Dashboard / KPI Layer\n\n**Business behavior**\n- KPI cards, charts, tables, task lists, alerts, AI insights.\n- Role-based homepages (CFO, Store Manager, Production Manager, Donor Manager, etc.).\n- Drill-down: from KPI → summary list → specific transaction.\n\n**Technical**\n- Dashboard definitions are metadata objects referencing queries.\n- Widgets can consume both structured data (SQL) and AI insights.\n- Access to each widget respects permissions.\n\n### 9.3 Predictive / Prescriptive Insights\n\n**Business behavior**\n- Forecast demand, stockout risk, budget overruns, missed sales targets.\n- Alert managers early and suggest concrete actions.\n\n**Technical**\n- AI layer + historical KPI data.\n- Event bus emits warnings which can trigger workflow steps (escalate, create task, request approval, etc.).\n\n---\n\n## 10. AI Companion\n\n### 10.1 User Experience\n\n**Business behavior**\n- A floating assistant panel:\n  - Available anywhere.\n  - Knows what record/module you’re on.\n  - Can proactively show “Attention needed” alerts.\n\n**Examples**\n- "Show me overdue invoices by customer for this company."\n- "Explain why this PO is blocked."\n- "Summarize spend vs budget for Program Alpha."\n- "Is this supplier high risk?" (AI looks at QC flags, late deliveries.)\n- "What is the leave carryover policy?"\n\n### 10.2 Technical\n\n- Uses local LLM(s) for reasoning and natural language, no dependency on external paid APIs.\n- Retrieval layer:\n  - Knows how to query entities according to metadata.\n  - Pulls policy documents.\n  - Respects role-based permissions.\n- Event bus signals can push alerts into AI panel.\n- AI suggestions can trigger workflows (e.g. "Generate Purchase Request to restock Item A").\n\n---\n\n## 11. Security, Roles, Compliance\n\n### 11.1 Roles & Permissions\n\n**Business behavior**\n- Roles are not hardcoded. Admins can define roles per company.\n- Permissions can be:\n  - Module-level (view/create in Procurement).\n  - Action-level (approve PO > $5,000).\n  - Field-level (can view Salary?).\n  - Record-scope (can access Company A, cannot access Company B).\n\n**Technical**\n- Permission matrix is metadata-driven and can be edited visually.\n- Every field definition can carry visibility rules per role.\n- AI inherits the same visibility rules.\n\n### 11.2 Audit & Traceability\n\n**Business behavior**\n- We audit:\n  - Who approved.\n  - Who posted journal entries.\n  - Who modified schema.\n  - Who imported data.\n  - Who rolled back staging.\n- Finance data has immutable trails.\n- Staging-to-live promotions are logged.\n\n**Technical**\n- Audit logs reference entity IDs, user IDs, timestamps, and old/new values.\n- Schema changes and workflow changes are versioned objects with rollback.\n- Migration sessions store checksums of source files.\n\n### 11.3 Budgetary & Process Control\n\n**Business behavior**\n- PR/PO approval checks budget availability.\n- Sales dashboards compare target vs actual.\n- NGO spend checks donor allocation.\n- Exceptions escalate automatically.\n\n**Technical**\n- Workflow engine calls Budget module before approving spend.\n- Cost Center/Budget snapshots drive alert thresholds.\n- Escalations emit event bus messages that trigger notifications/tasks.\n\n### 11.4 Localization / Compliance\n\n**Business behavior**\n- Multi-language UI.\n- Region-specific VAT/GST.\n- Payroll localization (tax, social security, etc.).\n- Grant reporting formats for donors.\n- Quality/compliance checkpoints for production.\n\n**Technical**\n- Industry Packs can ship localized tax schemas and payroll components.\n- Localization metadata drives labels, date formats, number formats.\n\n---\n\n## 12. Deployment & Infrastructure\n\n### 12.1 Install Model\n\n**Business behavior**\n- Guided installer sets up DB, backend, web UI, AI runtime.\n- First admin is prompted to create the first company and choose Industry Pack.\n- Role templates and default dashboards are created.\n\n**Technical**\n- Installer provisions PostgreSQL, applies base migrations (metadata tables, core entities).\n- Seeds industry pack metadata.\n- Launches services (web app, workflow engine, AI runtime, event bus).\n\n### 12.2 Local Network Access / Offline\n\n**Business behavior**\n- Other staff connect over LAN via browser.\n- Offline PWA for warehouse/factory/mobile: local caching + queued transactions.\n\n**Technical**\n- Web frontend runs as PWA.\n- Sync service queues writes and resolves conflicts on reconnect.\n- Reverse proxy or tunnel can be configured to allow secure remote access.\n\n### 12.3 Hardware Guidance\n\n**Small to mid team usage**\n- ~32GB RAM, SSD/NVMe, mid-range CPU, optional mid-tier GPU for AI.\n- Windows 11 Pro or Linux.\n\n**Larger usage**\n- 64GB+ RAM, higher core-count CPU, redundant SSD storage, GPU acceleration.\n- Linux preferred for stability and AI performance.\n\n---\n\n## 13. Implementation Phases\n\n**Phase 0: Multi-company architecture planning**\n- Define multi-company data isolation, inter-company postings, consolidation logic.\n\n**Phase 1: Platform foundation**\n- Metadata engine, schema designer, workflow engine, permissions, company registry.\n\n**Phase 2: Core operational modules**\n- Finance (GL/AP/AR), Procurement, Inventory, Sales.\n- End-to-end Procure-to-Pay and Order-to-Cash.\n- Dashboards and audit logs.\n\n**Phase 3: Data Migration Engine rollout**\n- Upload → Detect → Map → Clean → Stage → Approve → Commit → Rollback.\n- Schema extension on import.\n\n**Phase 4: No-code builders**\n- Form Builder, Custom Module Builder, Workflow Studio, Dashboard Builder.\n- Allow admins to extend/automate without dev.\n\n**Phase 5: AI companion**\n- Context-aware assistant panel.\n- Predictive alerts (budget overrun, stockout, SLA breach).\n\n**Phase 6: Advanced/vertical modules**\n- Manufacturing module, NGO/Grant Management, Cost Center & Budget Control, Project/Task, HR & Payroll, Asset Management, Policy/Document, Quality/Compliance, SLA/Service.\n\n**Phase 7: Security, training, UAT**\n- Permissions hardening.\n- User education.\n- End-to-end reconciliation with legacy balances.\n\n**Phase 8: Pilot go-live**\n- One company goes live.\n- Monitor.\n- Fix blockers.\n\n**Phase 9: Rollout to all companies**\n- Onboard more companies/branches using Industry Packs + saved migration mappings.\n- Turn on consolidation.\n\n**Phase 10: Hypercare**\n- Stabilize, support, iterate dashboards and workflows.\n\n---\n\n## 14. Strategic Differentiators\n\n- **Industry-ready from Day 1:** No blank ERP. Company creation = working template.\n- **Schema that evolves itself:** Migration can extend the data model automatically.\n- **No-code everywhere:** Admins can create fields, modules, workflows, dashboards.\n- **Finance-safe flexibility:** You can add analytics on finance objects without breaking audit trails.\n- **Multi-company aware:** Inter-company flows + consolidation built in.\n- **AI-native + private:** Embedded assistant, proactive alerts, no per-token billing.\n- **Runs on normal hardware:** LAN-first, offline-capable, no forced cloud.\n\nThis is the complete functional + technical blueprint for the ERP platform.\n",
  },
  {
    "title": "finance_transactions_readiness.md",
    "content": "## Finance Transaction Entry Readiness\n\nThe finance posting pipeline has been hardened for production use.\n\n### Voucher Numbering & Sequencing\n\n- New table `finance_journalsequence` issues per-company, per-journal running numbers.\n- Journal vouchers now store `sequence_number` alongside the human-friendly `voucher_number`.\n\n### Journal Service Rules\n\n- `JournalService.create_journal_voucher` validates that:\n  - All accounts belong to the same company and allow direct posting.\n  - Debit and credit values are positive, exclusive, and balanced.\n  - Voucher numbers are automatically generated in the format `{JOURNAL_CODE}-{FISCAL_YEAR}-{####}`.\n- Entries are created in bulk to preserve ordering and atomicity.\n\n- `JournalService.post_journal_voucher` now locks the voucher, entries, and accounts before updating balances and re-validates the double-entry totals prior to posting.\n\n### Invoice Posting\n\n- Supplier and sales invoices pass the posting user as the journal creator, ensuring audit trails remain intact.\n\n### Outstanding Tasks\n\n- Configure purchase (`PURCHASE`), sales (`SALES`), and general (`GENERAL`) journals per company.\n- Flag any master data (suppliers, customers, accounts) missing required ledger mappings before go-live.\n"
  },
  {
    "title": "new_phase0,1.md",
    "content": "# Twist ERP Platform - Phase 0 & 1 Blueprint\n\nThis document provides the engineering blueprint for Phase 0 (Multi-Company Architecture) and Phase 1 (Platform Foundation) of the Twist ERP platform. It translates product intent into concrete technical deliverables, guardrails, and acceptance criteria so that implementation teams can execute without ambiguity.\n\n---\n\n## 1. Guiding Outcomes\n\n- Single-machine installation that bootstraps an embedded PostgreSQL instance and provisions tenant databases without manual DBA work.\n- CompanyGroup tenancy model that isolates unrelated businesses while enabling real-time inter-company flows inside each group.\n- Metadata-first platform foundation (schema, workflows, permissions) that Phase 2 functional modules can rely on immediately.\n- Audit, backup, and observability hooks in place from the outset to keep later phases stable.\n\n---\n\n## 2. Phase 0 - Multi-Company Architecture Skeleton\n\n### 2.1 Objectives\n\n- Stand up the embedded database runtime and provisioning flow.\n- Define and persist CompanyGroup tenancy, company context, and inter-company plumbing.\n- Establish metadata layering and audit logging foundations.\n- Ship minimal admin tooling (CLI or scripts acceptable) for backup and basic health checks.\n\n### 2.2 Embedded PostgreSQL Runtime\n\n**Scope**\n\n- Bundle PostgreSQL binaries for supported platforms and install a managed instance on first run.\n- Initialize a dedicated data directory (default port `5433`, `listen_addresses = 'localhost'`).\n- Create the global system database `twist_system` and, when requested, additional CompanyGroup databases (for example `cg_<slug>`).\n\n**Security and Access**\n\n- Generate a superuser credential during install and store it encrypted (machine keystore or sealed secrets file).\n- Application services authenticate with least-privilege roles per database.\n- Only the provisioning or migration service can use elevated credentials to create databases or apply schema migrations.\n\n**Operations**\n\n- Provide a CLI or admin endpoint for:\n  - `db status` - verify instance is running and reachable.\n  - `db backup` - create dumps of `twist_system` and all CompanyGroup databases as a single artifact.\n  - `db start` / `db stop` - manage the managed Postgres service (optional in Phase 0 but recommended if effort allows).\n- Emit structured logs for lifecycle events (initialization, start, stop, backup success or failure).\n\n### 2.3 CompanyGroup (Tenant Cluster) Model\n\n**Concept**\n\n- CompanyGroup is the tenancy boundary. Companies inside the same group share a database and can transact with one another; companies in different groups remain fully isolated.\n\n**Persistence**\n\n- `twist_system.company_groups` table fields:\n  - `company_group_id` (UUID primary key)\n  - `group_name`\n  - `db_name` (physical Postgres database identifier)\n  - `industry_pack_type` (manufacturing, NGO, trading, service, ...)\n  - `supports_intercompany` (boolean)\n  - `status`\n  - `created_at`, `updated_at`\n- `twist_system.company_group_settings` for shared configuration (timezone, base currency, reporting calendar, and similar items).\n\n**Provisioning Flow**\n\n1. Request to create a CompanyGroup arrives (wizard or CLI).\n2. System database stores the metadata row (status = `creating`).\n3. Provisioning service creates the physical Postgres database, runs baseline migrations, seeds industry-pack metadata.\n4. Default admin role and service accounts are created for the group.\n5. Status flips to `active`; audit entry recorded.\n\n### 2.4 Company Model and Context\n\n- `cg_<slug>.companies` table with:\n  - `company_id` (UUID primary key)\n  - `company_group_id` (foreign key back to system database)\n  - `legal_name`, `short_code`, `currency`, `timezone`, `is_active`, timestamps.\n- Every transactional table inside a CompanyGroup database includes `company_id` and `company_group_id`.\n- Runtime context middleware resolves for every request:\n  - Authenticated user.\n  - Active CompanyGroup and Company (from headers or token claims).\n  - Optional cross-company visibility flag (for group-level roles).\n\n### 2.5 Inter-Company Transaction Framework\n\n- Introduce `inter_company_txn_id` to link mirrored AR/AP or inventory movements.\n- Create `cg_<slug>.inter_company_links` with:\n  - `link_id` (UUID primary key)\n  - `initiating_company_id`\n  - `counterparty_company_id`\n  - `source_entity` (invoice, stock_transfer, ...)\n  - `source_record_id`\n  - `status` (pending, confirmed, canceled)\n  - timestamps\n- Add group-level GL mapping table `cg_<slug>.group_account_map` to tie local accounts to a consolidated chart and flag inter-company accounts used for eliminations.\n\n### 2.6 Metadata Layering Strategy\n\n- Four-layer model:\n  1. Core system (ships with codebase).\n  2. Industry pack baseline (selected per CompanyGroup).\n  3. Group customization (applies to all companies in the group).\n  4. Company override (final adjustments per company).\n- Store metadata definitions using versioned JSON (entity definitions, field schemas, form layouts, workflow templates).\n- Provide merge logic that produces an effective definition per request context and records the version used for audit.\n\n### 2.7 Security, Permissions, and Audit Baseline\n\n- Adopt custom `users.User` model with:\n  - `is_system_admin`, `is_staff`, `is_active`.\n  - Many-to-many `companies` via `user_company_roles` containing `role_id`.\n- Enforce access by:\n  - Checking a user has an active role for the target company.\n  - Allowing group-level roles to operate across companies where permitted (`can_view_all_companies`).\n- Audit logging requirements:\n  - Record user, company, company group, entity, action, before/after (where feasible), correlation identifiers.\n  - Minimum storage: append-only table `cg_<slug>.audit_log`.\n\n### 2.8 Observability and Guardrails\n\n- Application-level health endpoint should confirm:\n  - Database connectivity for system database and current CompanyGroup.\n  - Background services (workflow engine, job runner) heartbeat (stubbed if not yet implemented).\n- Metrics hooks (even if only counters) for database provisioning time, backup duration, failed authentication attempts.\n\n### 2.9 Phase 0 Exit Criteria\n\n- Embedded Postgres service can be installed, started, stopped, and backed up without manual DBA steps.\n- CompanyGroup provisioning creates both metadata and physical database with baseline schema.\n- Multi-company session context enforced across the API stack.\n- Metadata layering persists and can render an effective definition sample (API or CLI).\n- Audit log captures authentication and provisioning events.\n- Documentation and runbook for installation, backup, and troubleshooting delivered.\n\n---\n\n## 3. Phase 1 - Platform Foundation\n\n### 3.1 Objectives\n\n- Deliver onboarding experience that provisions CompanyGroups, companies, and the first administrators end-to-end.\n- Provide tooling for schema customization, workflow orchestration, and role-based access control.\n- Implement runtime metadata merge and hybrid storage model to support future module extensibility.\n- Surface an internal admin console for operating the platform day to day.\n\n### 3.2 Core Workstreams\n\n#### 3.2.1 Onboarding Wizard\n\n- **Flows**\n  1. Select or create CompanyGroup; choose industry pack.\n  2. Name the primary company and set default currency and timezone.\n  3. Create first admin user (credentials and optional MFA bootstrap).\n  4. Review summary and provision.\n- **Backend responsibilities**\n  - Trigger CompanyGroup provisioning pipeline; either block UI until complete or provide progress feedback.\n  - Assign admin user to group and company with superuser-equivalent role.\n  - Seed demo data where relevant (chart of accounts, approval workflows).\n- **Deliverables**\n  - REST endpoints with idempotency controls.\n  - Frontend wizard with validation and failure recovery.\n  - Audit trail entry capturing wizard actions.\n\n#### 3.2.2 Metadata-Driven Schema Designer (MVP)\n\n- Service and lightweight UI to list entities and fields drawn from merged metadata.\n- Support CRUD on custom fields:\n  - Field name, label, datatype, default, required flag, display rules.\n  - Persist definition at appropriate layer (group versus company).\n- Newly created fields stored initially in `extra_data` JSONB on transactional tables.\n- Emit events when metadata changes for downstream cache invalidation.\n\n#### 3.2.3 Hybrid Storage and Promotion Path\n\n- Standard structure for core tables:\n  - Base columns defined in migrations.\n  - `extra_data` JSONB column for flexible attributes.\n- Implement backend job to promote a JSONB field into a real column:\n  - Validate data type and nullability.\n  - Run `ALTER TABLE` within maintenance window.\n  - Backfill existing data.\n  - Update metadata to mark field as `storage_mode = column`.\n  - Provide rollback guidance if migration fails.\n\n#### 3.2.4 Workflow Engine Core\n\n- Metadata models:\n  - `workflow_definitions` (graph of states, transitions, conditions).\n  - `workflow_versions` (immutable snapshots).\n  - `workflow_assignments` (map workflows to entities or companies).\n- Runtime service responsibilities:\n  - Subscribe to domain events (`PR.CREATED`, `INVOICE.POSTED`, and similar).\n  - Evaluate rules, escalate approvals, notify participants.\n  - Persist workflow instances and action logs with audit context.\n- Provide admin UI to view workflow graph and current instances (read-only acceptable for Phase 1).\n\n#### 3.2.5 Permission Matrix and Role Management\n\n- Define `role_definitions` per CompanyGroup with modules, actions, and field-level permissions.\n- Extend `user_company_roles` with attributes:\n  - `role_id`, `company_id`, `is_active`, `assigned_at`.\n  - Flags such as `can_switch_company`, `can_manage_metadata`.\n- Build admin screens and APIs to:\n  - Assign users to roles and companies.\n  - Clone roles across companies.\n  - Preview effective permissions for a user.\n- Enforce permissions inside API endpoints and workflow engine hooks.\n\n#### 3.2.6 Runtime Metadata Merge Service\n\n- Implement deterministic merge order (Core → Industry Pack → Group Custom → Company Override).\n- Cache effective definitions per entity and company (invalidate on changes).\n- Provide API to fetch effective schema, form layout, and workflow selection.\n- Include version hash so clients can detect changes and refresh UI automatically.\n\n#### 3.2.7 Admin Console (MVP)\n\n- Web-based internal tool (can live inside existing frontend workspace) with modules:\n  - Dashboard: system status, database health, pending provisioning tasks.\n  - Tenancy: list CompanyGroups and companies, create or disable entities.\n  - Users and Roles: manage assignments, reset passwords, view audit trail.\n  - Metadata: view definitions, create custom fields, trigger promotions.\n  - Workflows: list definitions, inspect running instances.\n  - Maintenance: trigger backups, download support bundles.\n- Authentication restricted to system admins and group-level admins.\n\n### 3.3 Supporting Infrastructure\n\n- **Background workers**: Celery or equivalent with Redis to run provisioning, workflow, and promotion tasks asynchronously.\n- **Event bus**: Define minimum set of domain events (for example `company.created`, `user.invited`, `metadata.updated`) and message contracts.\n- **Testing and QA**:\n  - Fixture data for integration tests across multiple companies within a group.\n  - Automated test harness for metadata merge scenarios.\n  - Load test scripts for onboarding wizard to validate provisioning concurrency.\n\n### 3.4 Phase 1 Exit Criteria\n\n- Onboarding wizard provisions a new CompanyGroup, company, admin user, and baseline metadata entirely through UI or API.\n- Schema designer supports creating and editing custom fields stored in JSONB.\n- Promotion workflow can move a custom field from JSONB to native column with audit trail.\n- Workflow engine executes approval flows and stores state transitions.\n- Permission matrix enforces module or action level security and supports cross-company roles.\n- Runtime metadata merge returns correct effective definitions; cache invalidation works.\n- Admin console exposes tenancy, user management, metadata, workflow, and maintenance views.\n- Backup command integrates with admin console (or exposed API) and is documented.\n\n---\n\n## 4. Implementation Milestones\n\n| Milestone                  | Duration | Key Deliverables                                         |\n|--------------------------|--------|--------------------------------------------------------|\n| Phase 0 Kickoff            | Week 0   | Environment setup, embedded Postgres packaging plan      |\n| Embedded DB GA             | Week 2   | Automated init, start, backup scripts, health checks     |\n| CompanyGroup MVP           | Week 4   | System database schema, provisioning flow, audit logging |\n| Phase 0 Exit               | Week 6   | Sign-off on tenancy, metadata skeleton, runbook          |\n| Phase 1 Kickoff            | Week 6   | Cross-team alignment, backlog finalization               |\n| Onboarding Wizard Alpha    | Week 8   | UI flow, provisioning pipeline integration               |\n| Metadata and Workflow Beta | Week 10  | Schema designer, workflow runtime                        |\n| Admin Console Beta         | Week 11  | Core admin features, permission guardrails               |\n| Phase 1 Exit               | Week 12  | All exit criteria met, docs and testing complete         |\n\n---\n\n## 5. Risks and Mitigations\n\n- **Embedded Postgres packaging complexity** - Prototype installer early; document OS-specific steps; provide fallback Docker compose for development.\n- **Schema promotion downtime** - Enforce maintenance windows, wrap migrations in transactions, maintain backup before promotion.\n- **Metadata merge correctness** - Build comprehensive unit tests and deterministic ordering; log merge decisions for debugging.\n- **Workflow engine scalability** - Start with synchronous path but design queue-friendly architecture; benchmark before Phase 2 load increases.\n- **Role explosion** - Establish naming convention and role templates; admin console must support cloning and diffing roles.\n\n---\n\n## 6. Deliverables Checklist\n\n- Installation runbook covering embedded database lifecycle.\n- API and CLI documentation for provisioning, metadata, workflow, permissions.\n- Seed data for industry packs and default roles.\n- Automated test suite results and coverage summary.\n- Architecture decision records for key choices (embedded DB, metadata merge, promotion flow).\n- Operational handoff notes: backup restore drill, audit log retention, monitoring setup.\n\n---\n\n## 7. Next Steps After Phase 1\n\n- Kick off Phase 2 module implementation (Finance, Procurement, Sales, Inventory) using metadata, workflow, and RBAC foundations.\n- Expand observability (metrics dashboard, alerting) based on Phase 1 instrumentation.\n- Plan Phase 3 data migration tooling using backup and export capabilities built in Phases 0 and 1.\n\n---\n\n**Version**: 1.0  \n**Last Updated**: October 2025  \n**Owners**: Platform Architecture, Core Engineering, DevOps\n\nAwesome. Phase 2 is where Twist ERP stops being just a platform and actually starts behaving like a working ERP.\n\nBy the end of Phase 2:\n\n- A company in a CompanyGroup can buy something, receive it, stock it, sell it, invoice it, collect money, and have everything post to ledgers with audit and approvals enforced.\n- Group finance (CFO role) can see live status across companies in that group.\n- All of this runs on the architecture we already locked in (Postgres per CompanyGroup, metadata-driven forms/workflows, RBAC, audit).\n\nI’ll break Phase 2 into the major deliverables you listed and define: scope, data model, workflows, role/security, posting logic, and integration points for each.\n\n## Phase 2 Modules\n\n- 2.1 Finance (GL / AP / AR)\n- 2.2 Procurement (PR → PO → GRN → Bill → Payment)\n- 2.3 Sales / Order-to-Cash (Quotation → Sales Order → Delivery → Invoice → Receipt)\n- 2.4 Inventory & Warehouse\n- 2.5 Group dashboards + Cross-module audit visibility\n\nWe’re implementing all of these inside each CompanyGroup database (`cg_*`), using:\n\n- `company_id` on all transactional records\n- Workflow Engine from Phase 1\n- RoleDefinition permissions from Phase 1\n- AuditLog from Phase 1\n\n---\n\n## 2.1 Finance Module (GL / AP / AR)\n\n### 2.1.1 Scope\n\nFinance in Phase 2 must support:\n\n- Chart of Accounts (CoA) per company, mapped to GroupAccountMap for consolidation.\n- General Ledger postings.\n- Accounts Payable:\n\n  - Supplier Bills\n  - Payables aging\n  - Payment posting\n\n- Accounts Receivable:\n\n  - Customer Invoices\n  - Receivables aging\n  - Collection/receipt posting\n\n- Audit trail: who approved, who posted.\n- Inter-company tagging (for elimination later).\n\n### 2.1.2 Core data tables in `cg_*` DB\n\n**ChartOfAccounts**\n\n- `account_id` UUID PK\n- `company_id`\n- `account_code` text\n- `account_name` text\n- `account_type` text (Asset, Liability, Equity, Income, Expense)\n- `is_intercompany` bool\n- `group_account_code` text (for consolidation / elimination)\n- `status`\n- timestamps\n\n**GLEntry**\n\n- `gl_entry_id` UUID PK\n- `company_id`\n- `posting_date`\n- `account_id`\n- `debit_amount` numeric(18,2)\n- `credit_amount` numeric(18,2)\n- `currency`\n- `reference_type` (e.g. "AP_BILL", "AR_INVOICE", "JOURNAL")\n- `reference_id`\n- `inter_company_txn_id` (nullable, link if inter-company)\n- `created_by_user_id`\n- `created_at`\n- `extra_data` jsonb\n\nAll postings result in rows in GLEntry.\n\n**APBill (Supplier Invoice)**\n\n- `ap_bill_id` UUID PK\n- `company_id`\n- `supplier_id`\n- `bill_date`\n- `due_date`\n- `currency`\n- `status` ("draft", "approved", "posted", "paid")\n- `total_amount`\n- `extra_data` jsonb\n- timestamps\n- link to GRN/PO lines if originated from procurement\n\n**APPayment**\n\n- `ap_payment_id` UUID PK\n- `company_id`\n- `ap_bill_id`\n- `paid_amount`\n- `payment_date`\n- `payment_method` (bank/cash)\n- timestamps\n\n**ARInvoice (Customer Invoice)**\n\n- `ar_invoice_id` UUID PK\n- `company_id`\n- `customer_id`\n- `invoice_date`\n- `due_date`\n- `currency`\n- `status` ("draft","approved","posted","collected","writeoff_pending")\n- `total_amount`\n- `inter_company_txn_id` (if selling to sister company)\n- `extra_data` jsonb\n- timestamps\n\n**ARReceipt**\n\n- `ar_receipt_id` UUID PK\n- `company_id`\n- `ar_invoice_id`\n- `received_amount`\n- `receipt_date`\n- `payment_method`\n- timestamps\n\nYou’ll also have master data:\n\n- `supplier` table (similar to `customer`)\n- `bank_account` / `cash_account` reference\n- tax tables if needed\n\n### 2.1.3 Posting rules\n\nFor each “financial event” we generate GLEntry rows:\n\n- APBill posted:\n\n  - Debit Expense or Inventory\n  - Credit AP Control account\n\n- APPayment posted:\n\n  - Debit AP Control\n  - Credit Bank/Cash\n\n- ARInvoice posted:\n\n  - Debit AR Control\n  - Credit Revenue\n\n- ARReceipt posted:\n\n  - Debit Bank/Cash\n  - Credit AR Control\n\n- Inventory movement (from Inventory module) posts to stock/COGS accounts\n\nThese posting mappings must be configurable by company:\n\n- In metadata, define Posting Rules per document type.\n  Example: `posting_rules_json` in metadata for `APBill`:\n\n  ```json\n  {\n\t"lines": [\n\t\t{\n\t\t\t"dr": "inventory_account_id",\n\t\t\t"cr": "ap_control_account_id",\n\t\t\t"basis": "line_amount"\n\t\t}\n\t]\n  }\n  ```\n\nPhase 2 must:\n\n- Read posting rules from metadata (Company Override layer can change accounts).\n- Generate balanced debit/credit GLEntry rows.\n- Log the fact that posting happened (AuditLog entry with action_type=\"POST_GL\").\n\n### 2.1.4 Approvals & workflow\n\nAP Bills, AR Invoices, and Manual Journals must pass through Workflow Engine from Phase 1:\n\n- When APBill is submitted:\n\n  - Fire event `APBILL.SUBMITTED`.\n  - WorkflowDefinition for APBill decides:\n\n    - If amount > threshold, require CFO approval.\n    - If supplier is “new vendor”, require Compliance approval.\n\n  - Store state in workflow instance (pending approvals).\n  - When fully approved, mark `status=\"approved\"`.\n  - Only approved bills can be posted to GL.\n\nSame for ARInvoice and for manual Journals.\n\nAll approval steps write to AuditLog.\n\n### 2.1.5 Aging and basic finance reports\n\nPhase 2 must generate:\n\n- AP aging (per supplier, total outstanding by aging bucket).\n- AR aging (per customer).\n- Trial balance (sum of GLEntry per account for a date range).\n- P&L and Balance Sheet per company:\n\n  - Summarize accounts by `account_type`.\n\n- Group trial balance (for Group CFO role across companies in same CompanyGroup):\n\n  - Summarize per company_id, map to `group_account_code`, include `is_intercompany`.\n  - This sets you up for consolidation/elimination reports.\n\nThese queries stay within the same `cg_*` DB.\n\n---\n\n## 2.2 Procurement (PR → PO → GRN → Bill → Payment)\n\n### 2.2.1 Scope\n\nProcurement flow inside one company:\n\n1. Purchase Requisition (PR) – request to buy\n2. Purchase Order (PO) – approved order to supplier\n3. Goods Receipt Note (GRN) – items physically received into stock\n4. Supplier Bill (APBill) – invoice from supplier\n5. Payment (APPayment)\n\nThis must integrate Inventory (stock levels, valuation) and Finance (AP).\n\nAlso supports inter-company if supplier is actually another company in the same CompanyGroup.\n\n### 2.2.2 Core tables in `cg_*` DB\n\n**PurchaseRequisition**\n\n- `pr_id` UUID PK\n- `company_id`\n- `requested_by_user_id`\n- `request_date`\n- `status` ("draft","submitted","approved","rejected","converted_to_po")\n- `total_estimated_amount`\n- `extra_data` jsonb\n- timestamps\n\n**PurchaseOrder**\n\n- `po_id` UUID PK\n- `company_id`\n- `supplier_id` (or sister company’s company_id if inter-company)\n- `po_date`\n- `status` ("draft","approved","sent","partially_received","closed")\n- `currency`\n- `total_amount`\n- `inter_company_txn_id` (nullable)\n- `extra_data` jsonb\n- timestamps\n\n**PurchaseOrderLine**\n\n- `po_line_id` UUID PK\n- `po_id` FK\n- `item_id`\n- `description`\n- `qty_ordered`\n- `price`\n- `uom`\n- `expected_delivery_date`\n- `company_id`\n- timestamps\n- `extra_data` jsonb\n\n**GoodsReceiptNote (GRN)**\n\n- `grn_id` UUID PK\n- `company_id`\n- `po_id`\n- `received_date`\n- `status` ("draft","posted")\n- timestamps\n\n**GRNLine**\n\n- `grn_line_id` UUID PK\n- `grn_id`\n- `po_line_id`\n- `item_id`\n- `qty_received`\n- `warehouse_id`\n- `company_id`\n- timestamps\n- `extra_data` jsonb\n\nFlow:\n\n- PR creates/requests items or services.\n- Approved PR → PO.\n- Received items create GRN lines → update Inventory.\n- Supplier sends invoice → APBill linked to PO/GRN.\n- Payment → APPayment.\n\n### 2.2.3 Workflow & approvals\n\n- PR approval routing:\n\n  - Use WorkflowEngine. Rules can be like:\n\n    - If total > X → Dept Head approval\n    - If CapEx category → CFO approval\n\n  - Only approved PR can become PO.\n\n- PO approval routing:\n\n  - Separate WorkflowDefinition for `PurchaseOrder`.\n  - After approval, mark `status=\"approved\"` and “PO sent”.\n\n- GRN posting:\n\n  - When GRN is posted, Inventory increases. See Inventory module section below.\n\n- AP Bill:\n\n  - APBill generated from PO/GRN.\n  - APBill approval uses Finance workflow (CFO/etc).\n  - When posted, it hits the GL (AP credit, Inventory or Expense debit).\n\n### 2.2.4 Inter-company procurement\n\nIf `supplier_id` represents another company in the same CompanyGroup:\n\n- Creating PO in Company B should:\n\n  - generate a mirror Sales Order in Company A (Sales module) and set a shared `inter_company_txn_id`.\n\n- Receiving GRN in Company B should:\n\n  - decrement stock in Company A (Delivery from A),\n  - increment stock in Company B,\n  - prepare ARInvoice in Company A / APBill in Company B.\n\nThis uses the `InterCompanyLink` table we defined in Phase 0.\nThat link must be filled in Phase 2 when PR→PO→GRN happens across companies.\n\n---\n\n## 2.3 Sales / Order-to-Cash\n\n### 2.3.1 Scope\n\nSales flow inside one company:\n\n1. Quotation / Offer\n2. Sales Order (SO)\n3. Delivery / Dispatch (ships goods, reduces Inventory)\n4. Customer Invoice (ARInvoice)\n5. Receipt / Collection (ARReceipt)\n\nAlso drives AR and revenue in Finance.\n\n### 2.3.2 Core tables in `cg_*` DB\n\n**SalesQuotation**\n\n- `quote_id` UUID PK\n- `company_id`\n- `customer_id`\n- `quote_date`\n- `status` ("draft","sent","accepted","rejected","expired")\n- `total_amount`\n- `currency`\n- `extra_data` jsonb\n- timestamps\n\n**SalesOrder**\n\n- `so_id` UUID PK\n- `company_id`\n- `customer_id`\n- `so_date`\n- `status` ("draft","approved","partially_delivered","closed")\n- `currency`\n- `total_amount`\n- `inter_company_txn_id` (nullable, if customer is sister company)\n- `extra_data` jsonb\n- timestamps\n\n**SalesOrderLine**\n\n- `so_line_id` UUID PK\n- `so_id`\n- `item_id`\n- `description`\n- `qty_ordered`\n- `price`\n- `uom`\n- `company_id`\n- timestamps\n- `extra_data` jsonb\n\n**DeliveryNote / Shipment**\n\n- `delivery_id` UUID PK\n- `company_id`\n- `so_id`\n- `delivered_date`\n- `status` ("draft","posted")\n- timestamps\n\n**DeliveryLine**\n\n- `delivery_line_id` UUID PK\n- `delivery_id`\n- `so_line_id`\n- `item_id`\n- `qty_delivered`\n- `warehouse_id`\n- `company_id`\n- timestamps\n- `extra_data` jsonb\n\n**ARInvoice** (already defined in Finance)\n\n- Will now be linked to the Sales Order / DeliveryNote\n\n**ARReceipt** (already defined in Finance)\n\n### 2.3.3 Workflow & approvals\n\n- Sales Order approval:\n\n  - WorkflowDefinition for `SalesOrder` can enforce:\n\n    - Credit check (Customer credit_limit vs outstanding AR)\n    - Discount approval if margin below threshold\n\n  - Only approved SO can generate Delivery.\n\n- Delivery posting:\n\n  - When DeliveryNote is posted:\n\n    - Inventory goes down for that warehouse (Inventory module).\n    - COGS and stock ledger posting is prepared for Finance.\n\n- Invoice:\n\n  - ARInvoice is generated from delivered quantities.\n  - ARInvoice approval follows Finance workflow.\n  - Posting creates GLEntry (Debit AR / Credit Revenue).\n\n- Receipt:\n\n  - Receiving money (ARReceipt) posts (Debit Bank / Credit AR).\n\n### 2.3.4 Inter-company sales\n\nIf `customer_id` actually represents another company in the same CompanyGroup:\n\n- Creating Sales Order in Company A should:\n\n  - create mirror Purchase Order in Company B and link both via `inter_company_txn_id`.\n\n- Delivery in Company A:\n\n  - triggers GRN in Company B.\n\n- ARInvoice in A:\n\n  - becomes APBill in B.\n\nAll linked through `InterCompanyLink`.\nFinance will tag those postings as inter-company for consolidation elimination later.\n\n---\n\n## 2.4 Inventory & Warehouse\n\n### 2.4.1 Scope\n\nInventory module must support:\n\n- Item master\n- Warehouse / location master\n- Stock ledger\n- On-hand quantity per item per warehouse\n- Valuation posting to Finance\n- Notifications / alerts (low stock, aging stock)\n\nThis module sits between Procurement and Sales.\n\n### 2.4.2 Core tables in `cg_*` DB\n\n**Item**\n\n- `item_id` UUID PK\n- `company_id`\n- `item_code`\n- `item_name`\n- `uom`\n- `item_type` ("raw", "finished", "service", etc.)\n- `valuation_method` ("FIFO", "MovingAvg", etc.)\n- `status`\n- `extra_data` jsonb (for industry-specific fields like GSM/shade for textile, batch/lot for pharma/food)\n- timestamps\n\n**Warehouse**\n\n- `warehouse_id` UUID PK\n- `company_id`\n- `warehouse_name`\n- `location_code`\n- `status`\n- timestamps\n\n**StockLedgerEntry**\n\n- `sle_id` UUID PK\n- `company_id`\n- `item_id`\n- `warehouse_id`\n- `txn_type` ("GRN_POST", "DELIVERY_POST", "ADJUSTMENT", etc.)\n- `txn_reference_type` ("GRN","DELIVERY","MANUAL_ADJ", etc.)\n- `txn_reference_id`\n- `posting_time`\n- `qty_in`\n- `qty_out`\n- `balance_qty_after_txn`\n- `unit_cost`\n- `total_cost`\n- timestamps\n- `extra_data` jsonb\n\nStockLedgerEntry is the atomic movement record:\n\n- GRN posting creates `qty_in`.\n- Delivery posting creates `qty_out`.\n- Adjustments create in/out as needed.\n\n**StockBalanceSnapshot** (optional optimization)\n\n- `company_id`\n- `item_id`\n- `warehouse_id`\n- `on_hand_qty`\n- `on_hand_value`\n- updated whenever we post stock moves.\n\n### 2.4.3 Integration with Procurement\n\nWhen a GRN is posted:\n\n- For each `GRNLine`:\n\n  - Create StockLedgerEntry with `qty_in`.\n  - Update StockBalanceSnapshot.\n  - Calculate cost (from PO price or valuation rules).\n\n- If item is stock-controlled, post to Finance:\n\n  - Debit Inventory Account\n  - Credit GRN Clearing / AP Accrual (depending on config)\n    This uses the posting rules in Finance.\n\n### 2.4.4 Integration with Sales\n\nWhen a DeliveryNote is posted:\n\n- For each DeliveryLine:\n\n  - Create StockLedgerEntry with `qty_out`.\n  - Update StockBalanceSnapshot.\n  - Compute cost of goods sold (COGS).\n\n- Post to Finance:\n\n  - Debit COGS\n  - Credit Inventory\n\n### 2.4.5 Alerts / dashboards\n\nInventory module in Phase 2 must generate:\n\n- Low stock alert (compare `on_hand_qty` vs `reorder_level` in Item metadata).\n- Slow-moving / aging stock report.\n- GRN pending QC / blocked stock (if we later add QC/Inspection in advanced phases).\n\nThese alerts can show up in a basic dashboard for Store/Warehouse roles.\n\n---\n\n## 2.5 Group Dashboards & Cross-Module Audit\n\n### 2.5.1 Group-level snapshots\n\nPhase 2 must produce dashboards for:\n\n- CFO / Finance Controller (role may have `can_view_multiple_companies_in_group = true`):\n\n  - Cash position per company (sum of bank/cash accounts from GL).\n  - AP aging summary per company.\n  - AR aging summary per company.\n  - Top overdue receivables.\n  - Stock valuation by item category (if valuation method allows it).\n  - Purchase commitments (open POs not yet received).\n  - Sales pipeline / open SO value.\n  - High-risk workflow blocks (PRs or Bills waiting > X days for approval).\n\nAll of this is computed inside the same CompanyGroup DB (single source) and filtered by `company_id` according to role.\n\n### 2.5.2 Cross-module audit timeline\n\nWe already log actions in `AuditLog`. In Phase 2 we extend it so you can reconstruct process history:\n\nFor any document (PO, GRN, APBill, ARInvoice, DeliveryNote, etc.), you must be able to pull:\n\n- Who created it (user_id, role, timestamp)\n- Who approved it (workflow steps from Workflow Engine)\n- When it was posted to GL\n- When inventory moved\n- If inter-company: the linked company/doc via `inter_company_txn_id`\n\nThis is not just “for security.” This is very important for disputes:\n\n- “Warehouse says they never received it.”\n- “Finance says invoice was already approved.”\n- “Subsidiary B says price was wrong from Subsidiary A.”\n\nSo in Phase 2:\n\n- Every critical state change must write an AuditLog row:\n\n  - `action_type` = "CREATE", "APPROVE", "POST_GL", "POST_STOCK", "CLOSE", etc.\n\n- Every AuditLog row must include:\n\n  - `company_id`\n  - `entity_name` ("PurchaseOrder", "GRN", etc.)\n  - `record_pk` (the PO ID, GRN ID, etc.)\n  - `user_id`\n  - snapshot of role(s) from session at that time in `metadata`\n\nThis gives you a full trace across Procurement → Inventory → Finance.\nThis also satisfies future UAT / audit readiness in Phase 7.\n\n---\n\n## Phase 2 Deliverables (What engineering must build)\n\nThis is the output of Phase 2. When Phase 2 is “done,” Twist ERP must have:\n\n### 1. Finance Core\n\n- Tables in each CompanyGroup DB for:\n\n  - ChartOfAccounts, GLEntry, APBill, APPayment, ARInvoice, ARReceipt.\n\n- Posting rules metadata per document type (e.g. APBill, ARInvoice) stored in metadata so it’s configurable.\n- Posting service that:\n\n  - Generates balanced GL entries.\n  - Tags inter-company transactions.\n\n- AP aging, AR aging, Trial Balance, P&L, Balance Sheet queries.\n- Workflow approval (via Workflow Engine) for APBill, ARInvoice, manual Journals.\n- AuditLog entries for approval, posting.\n\n### 2. Procurement Flow\n\n- Entities/tables for PurchaseRequisition, PurchaseOrder (+ lines), GRN (+ lines).\n- Workflow approvals for PR and PO.\n- GRN posting that:\n\n  - Updates Inventory (StockLedgerEntry, StockBalanceSnapshot).\n  - Can create APBill draft.\n\n- Link to Finance:\n\n  - APBill for supplier invoices.\n  - APPayment posting.\n\n- Inter-company: PO / GRN in Company B creates mirror Sales / Delivery in Company A via `inter_company_txn_id`.\n\n### 3. Sales / Order-to-Cash\n\n- Entities/tables for SalesQuotation, SalesOrder (+ lines), DeliveryNote (+ lines).\n- Workflow approvals for SalesOrder (credit/discount check).\n- Delivery posting:\n\n  - Reduces Inventory.\n  - Computes COGS.\n\n- ARInvoice generation from deliveries.\n- ARReceipt posting.\n- Inter-company: Sales in Company A mirrors Purchase in Company B.\n\n### 4. Inventory\n\n- Item master, Warehouse master.\n- StockLedgerEntry table and logic.\n- StockBalanceSnapshot updates on every inbound (GRN) / outbound (Delivery).\n- Valuation (Moving Avg or FIFO baseline to start).\n- Integration with Finance for inventory/COGS postings.\n- Low stock / slow-moving stock alerts.\n\n### 5. Group Dashboards\n\n- Summary queries for CFO role across all companies in the same CompanyGroup DB:\n\n  - Cash, AP aging, AR aging, stock value, open POs, open SOs, overdue approvals.\n\n- Respect role permissions:\n\n  - If role can view multiple companies, show aggregated.\n  - If not, filter by their `company_id`.\n\n### 6. Cross-Module Audit Trail\n\n- Every key state change (CREATE / APPROVE / POST_STOCK / POST_GL / CLOSE) logged in `AuditLog`.\n- `AuditLog` must include `user_id`, `company_id`, `entity_name`, `record_pk`, timestamp, and role context.\n- Must be possible to reconstruct end-to-end chain:\n\n  - PR → PO → GRN → APBill → APPayment\n  - SO → Delivery → ARInvoice → ARReceipt\n  - Inventory and GL postings along the way\n\n---\n\n## How Phase 2 sits on Phases 0 + 1\n\n- From Phase 0:\n\n  - You already have embedded Postgres per CompanyGroup.\n  - You already have Company / CompanyGroup / User / Role / Access.\n  - You already have inter-company linking concept and group-level account mapping.\n  - You already have audit plumbing and session scoping by `company_id`.\n  - You already have RBAC and field-level visibility.\n\n- From Phase 1:\n\n  - You already have Schema Designer metadata (entity + fields).\n  - You already have `extra_data` JSONB fields and field promotion path for custom fields.\n  - You already have WorkflowDefinition + Workflow Engine runtime.\n  - You already have onboarding wizard to create a new CompanyGroup and seed Industry Pack.\n\n- Phase 2 now plugs in the first business workflows (Finance, Procurement, Sales, Inventory) directly on top of those foundations.\n\nAt the end of Phase 2, Twist ERP is no longer just “a platform.” It’s an actually usable ERP core for a multi-company group: buy → stock → sell → invoice → collect → post → report.\n\nPhase 3 is the Data Migration Engine.\n\nAfter Phase 3, Twist ERP should be able to pull in legacy data (Excel, CSV, old ERP exports) into any company inside any CompanyGroup — cleanly, safely, with minimal manual data entry, and without needing a developer/DBA.\n\nBelow is the full specification of Phase 3: entities, pipeline, workflow, permissions, rollback, metadata interaction, and deliverables.\n\n---\n\n## 3.0 Phase 3 Outcome\n\nBy the end of Phase 3, Twist ERP can:\n\n1. Let an authorized user upload legacy data files (customers, suppliers, items, stock balances, opening AR/AP, etc.).\n2. Detect the structure of the file and map its columns to Twist ERP entities/fields.\n3. Suggest new fields that don't exist yet — and safely extend metadata to handle them.\n4. Clean/normalize/validate rows (types, duplicates, referential links, required fields).\n5. Stage the data inside the CompanyGroup DB without touching live tables yet.\n6. Show the user exactly what will be imported and what will fail, with error queues they can fix.\n7. Require approval to commit.\n8. Commit atomically → write to the real tables (Customer, Supplier, Item, ARInvoice, etc.) and create GL/opening entries when applicable.\n9. Be able to roll back an import batch.\n\nAll of this must respect:\n\n- company_id scoping,\n- RBAC/permissions,\n- audit logging,\n- metadata layering (Industry Pack / Group Custom / Company Override).\n\n---\n\n## 3.1 Migration Personas / Roles\n\nWe define two roles that matter in Phase 3:\n\n### 1. **Data Importer**\n\n- Usually someone inside the company (e.g. finance lead, inventory controller).\n- Can start/import/stage data for _their_ company only.\n- Can fix validation errors and resubmit.\n- Cannot commit to live tables without approval.\n\nThis is a Company-level permission.\n\n### 2. **Migration Approver**\n\n- Usually Company Admin / Finance Controller / Group IT for that CompanyGroup.\n- Has permission to approve and finalize imports.\n- Can trigger commit of staged data into live tables.\n- Can authorize schema extension (new fields).\n\nThis role may have `can_view_multiple_companies_in_group = true` (like Group CFO or HQ IT), but we still log company_id for every import.\n\nBoth roles must be definable in `RoleDefinition.permissions` in the CompanyGroup DB.\n\n---\n\n## 3.2 The Migration Pipeline (Lifecycle)\n The migration process in Phase 3 is a pipeline with explicit stages. The engine must enforce that a batch moves in order, not skip steps.\n\n### Step 1. Upload\n\nUser uploads one or more source files for a specific company:\n\n- Allowed formats in Phase 3: CSV, XLSX.\n- Example use cases:\n\n  - Legacy Customer Master\n  - Supplier/Vendor Master\n  - Item Master\n  - Opening Stock by warehouse\n  - Opening AR (unpaid invoices)\n  - Opening AP (unpaid bills)\n  - Opening GL balances (optional if you allow cutover at trial balance level)\n\nAt upload time, user must choose:\n\n- Target company (must match active_company_id in session).\n- Target entity type they _think_ this is (e.g. “Customer”, “Item”, “Opening AR”, etc.) — OR “Unknown / Detect”.\n\nWe save the physical file (store reference in the CompanyGroup DB as metadata, not as raw blob if you want file system for size; store path + hash in DB).\n\n**Tables (in CompanyGroup DB):**\n\n- `migration_job`\n\n  - `migration_job_id` UUID PK\n  - `company_id`\n  - `entity_name_guess` ("customer", "item", "opening_ar", etc.)\n  - `status` ("uploaded","mapped","validated","approved","committed","rolled_back","error")\n  - `created_by_user_id`\n  - `created_at`\n  - `approved_by_user_id` (nullable)\n  - `approved_at` (nullable)\n  - `committed_at` (nullable)\n  - `rollback_parent_job_id` (nullable if this is a rollback attempt)\n  - `meta` jsonb (free-form job notes)\n\n- `migration_file`\n\n  - `file_id` UUID PK\n  - `migration_job_id`\n  - `original_filename`\n  - `stored_path` or reference\n  - `file_hash`\n  - `status` ("uploaded","parsed","error")\n  - `row_count_detected`\n  - timestamps\n\nAll uploads log to AuditLog (`action_type=\"IMPORT_UPLOAD\"` with job & file IDs).\n\n---\n\n### Step 2. Detect & Parse\n\nSystem inspects the uploaded file(s):\n\n- Parse headers.\n- Guess delimiter (for CSV).\n- Read first N rows.\n- Infer data types per column (string, numeric, date, money).\n- Try to guess which Twist ERP entity this corresponds to if not provided:\n\n  - e.g. columns `Customer Name`, `Address`, `Credit Limit` → likely "customer".\n  - columns `Item Code`, `UOM`, `Unit Cost`, `Warehouse` → likely "item" or "opening stock".\n\nWe store this parsed structure.\n\n**Tables:**\n\n- `migration_column_profile`\n\n  - `column_profile_id` UUID PK\n  - `migration_job_id`\n  - `column_name_in_file` text\n  - `detected_data_type` text ("text","number","date","money")\n  - `sample_values` jsonb (first few unique samples)\n  - `confidence_score` numeric\n  - timestamps\n\nStatus of `migration_job` can move from `"uploaded"` → `"mapped"` after column mapping is prepared.\n\n---\n\n### Step 3. Field Mapping\n\nNow we map file columns → Twist ERP entity fields.\n\nThis is where we integrate with metadata from Phase 1.\n\nFor the chosen entity (example: `Customer`):\n\n- Load merged effective entity definition for that company:\n\n  - Core + Industry Pack + Group Custom + Company Override.\n\n- That definition includes:\n\n  - Known field names\n  - Data types\n  - Required flags\n  - Visibility rules\n  - Whether a field is backed by a physical column or in `extra_data`.\n\nThe system should auto-suggest mappings:\n\n- `Customer Name` → `customer_name`\n- `CreditLimit` → `credit_limit`\n- `RegionCode` → `region_code` (doesn’t exist yet? propose new field)\n\nWe store the mapping.\n\n**Tables:**\n\n- `migration_field_mapping`\n\n  - `mapping_id` UUID PK\n  - `migration_job_id`\n  - `column_name_in_file`\n  - `target_entity_field` text (e.g. `customer_name`, `credit_limit`, `region_code`)\n  - `target_storage_mode` text ("column" | "extra_data_new_field" | "ignore")\n  - `new_field_definition_json` jsonb (if this creates a new custom field)\n  - `is_required_match` bool\n  - timestamps\n\nDetails:\n\n- `target_storage_mode=\"column\"` means this will fill an existing known field.\n- `target_storage_mode=\"extra_data_new_field\"` means we'll create a new field in metadata and store it in `extra_data` initially.\n- `"ignore"` means we won't import that column.\n\n**Important:**\nAt this stage, the system can propose schema extension:\n\n- If file has a column not in ERP (e.g. `RegionCode`), propose:\n\n  - `new_field_definition_json` with:\n\n    - `field_name`: "region_code"\n    - data type\n    - label\n    - visibility defaults\n    - which layer: company-level override\n\n- The Migration Approver can accept that new field.\n  When accepted:\n\n  - We update metadata (`EntityDefinition`) for this company with that new field (Company Override layer).\n  - That field will land in `extra_data` for now.\n\nWe must record this approval decision for audit (see 3.6).\n\n---\n\n### Step 4. Transform / Clean\n\nBefore staging, system normalizes values:\n\n- Trim whitespace.\n- Parse dates into ISO.\n- Convert money to decimal.\n- Normalize case where appropriate (e.g. uppercasing codes).\n- Map known enums (e.g. “Active”, “ACTIVE”, “A” → `active`).\n- Resolve foreign keys:\n\n  - e.g. for `opening stock` rows, `WarehouseName` must match an existing Warehouse in that company.\n  - for `AR open invoices`, `CustomerCode` must match an existing or newly-imported customer in the same job.\n\nWe create a staging table of clean rows.\n\n**Tables:**\n\n- `migration_staging_row`\n\n  - `staging_row_id` UUID PK\n  - `migration_job_id`\n  - `row_index_in_file` int\n  - `clean_payload_json` jsonb // keys = target fields after mapping/normalization\n  - `status` ("pending_validation","valid","invalid","skipped")\n  - timestamps\n\nNote: `clean_payload_json` is how we store each row after mapping to entity fields.\n\n---\n\n### Step 5. Validate\n\nRun validation rules on each staged row:\n\nValidation types:\n\n- **Required fields present?**\n  (e.g. `customer_name` is required)\n- **Data type valid?**\n  (`credit_limit` is numeric, etc.)\n- **Uniqueness / duplicates?**\n  (duplicate `customer_name` or `item_code`?)\n- **Referential integrity?**\n  (warehouse exists? customer exists for opening AR invoice?)\n- **Business rules?**\n  (e.g. credit limit cannot be negative; opening stock qty cannot be negative; invoice total must match sum of lines)\n\nStore validation results.\n\n**Tables:**\n\n- `migration_validation_error`\n\n  - `validation_error_id` UUID PK\n  - `migration_job_id`\n  - `staging_row_id`\n  - `error_code` text\n  - `error_message` text\n  - `severity` ("hard","soft")\n  - `suggested_fix` jsonb (optional, e.g. “use Warehouse=Main Warehouse”)\n  - timestamps\n\nRow status gets updated:\n\n- If no hard errors → `valid`.\n- If hard errors → `invalid`.\n- If row was intentionally skipped by user → `skipped`.\n\nThe UI must show a grid like:\n\n- Valid rows: will import.\n- Invalid rows: require fix or exclusion.\n- Summary totals: “125 rows valid, 7 invalid, 3 skipped.”\n\nUser with Data Importer role can now:\n\n- Edit values inline for invalid rows (fix typos, fix code mismatches).\n- Re-run validation for just those rows.\n- Mark certain rows `skipped`.`\n\nWhen all remaining rows are `valid` or `skipped`, job can move to approval step.\n\nAt this point `migration_job.status` changes from `"mapped"` → `"validated"`.\n\n---\n\n### Step 6. Approval\n\nBefore data touches live tables, require approval.\n\nWorkflow:\n\n- Fire event `MIGRATION_JOB.SUBMITTED_FOR_APPROVAL`.\n- Use the Workflow Engine (Phase 1) with a special workflow definition for import jobs.\n\n  - Example rule: If entity is `ChartOfAccounts` or `Opening AR/AP`, require Finance Controller approval.\n  - If entity is `Customer Master`, allow Company Admin to approve.\n  - If job affects multiple companies (not allowed in Phase 3; one job = one company), block.\n\nThe approver (Migration Approver role) reviews:\n\n- Summary totals (how many records will go in).\n- New fields that will be created.\n- Financial impact if applicable (e.g. opening AR totals, opening stock total value).\n- Audit preview.\n\nApprover can:\n\n- Approve → job moves to `"approved"`.\n- Reject → job goes back to `"validated"` with comments.\n\nApproval action writes to:\n\n- `migration_job.approved_by_user_id`\n- `migration_job.approved_at`\n- AuditLog with `action_type=\"IMPORT_APPROVED\"`.\n\n---\n\n### Step 7. Commit to Live Tables\n\nOn approval, the system performs the final import.\n\nFor each `migration_job` where `status=\"approved\"`:\n\n1. Start a DB transaction (inside that CompanyGroup DB).\n\n2. For each `migration_staging_row` with `status=\"valid\"`:\n\n   - Insert/Upsert into the target live table (e.g. `customer`, `item`, `ar_invoice`, etc.).\n\n     - Map known fields to columns.\n     - Write unknown/custom (approved) fields into `extra_data`.\n\n   - Capture the new PK of the created/updated live record.\n\n3. If the entity type triggers finance effects:\n\n   - Opening AR:\n\n     - For each imported unpaid invoice:\n\n       - Create `ARInvoice` with `status=\"posted\"`.\n       - Create corresponding `GLEntry` rows:\n\n         - Debit AR control account\n         - Credit Opening Balances / Retained Earnings / Migration Equity (configurable)\n\n   - Opening AP:\n\n     - Same idea but mirrored (Debit Opening Balances, Credit AP control).\n\n   - Opening Stock:\n\n     - For each row with qty and cost:\n\n       - Create `StockLedgerEntry` with `qty_in` and valuation.\n       - Post inventory value to GL (Debit Inventory, Credit Migration Equity).\n\n   - Opening GL balances (if you support trial balance import at go-live):\n\n     - Directly insert balanced `GLEntry` rows dated “opening date.”\n\n4. Mark `migration_job.status=\"committed\"`.\n\n5. Write `migration_commit_log` (see below).\n\n6. Commit DB transaction.\n\n**Tables:**\n\n- `migration_commit_log`\n\n  - `commit_id` UUID PK\n  - `migration_job_id`\n  - `committed_at` timestamptz\n  - `committed_by_user_id`\n  - `record_count_committed`\n  - `gl_impact_summary_json` (totals per account if applicable)\n  - `notes`\n  - timestamps\n\nAlso write AuditLog entries per affected entity row:\n\n- `action_type=\"IMPORT_COMMIT\"`\n- Include migration_job_id, record_pk, company_id, who committed.\n\n---\n\n### Step 8. Rollback\n\nWe need controlled rollback, but not casual undo.\n\nRollback is allowed for:\n\n- Master data (customers, suppliers, items) inserted in this batch.\n- Opening balances (AR/AP/Stock/GL) inserted in this batch.\n\nRules:\n\n- Only Migration Approver (or higher) can request rollback.\n- Rollback is “all or nothing” per job, not row-by-row.\n- Rollback is only allowed if:\n\n  - Those imported records have not been referenced by new transactions later.\n\n    - e.g. customer imported, then already used in a SalesOrder → cannot safely delete.\n\n  - Those GL entries are still isolated to this import batch.\n\nRollback process:\n\n1. System checks referential usage.\n\n2. If safe:\n\n   - Start transaction.\n   - Reverse all inserted master rows where possible (delete those customers/items/ar_invoices/etc.).\n   - Reverse GL entries (post reversing journal or delete if allowed pre-go-live).\n\n     - For AR/AP opening, reversing means credit AR/debit equity etc.\n     - For stock opening, create outbound StockLedgerEntry to bring stock to zero and post reversing GL.\n\n   - Mark `migration_job.status=\"rolled_back\"`.\n   - Create a new `migration_job` as rollback record with `rollback_parent_job_id` pointing to original.\n\n3. Log to AuditLog with `action_type=\"IMPORT_ROLLBACK\"`.\n\nRollback must be explicit and fully audited.\n\n---\n\n## 3.3 Integration With Metadata Layer\n\nPhase 3 must integrate tightly with the metadata system from Phase 1:\n\n### Auto-suggest new fields\n\nWhen mapping file columns → entity fields:\n\n- If column doesn't match any known field in that entity’s current merged definition:\n\n  - Prepare a proposed `new_field_definition_json`:\n\n    - `field_name` (machine key)\n    - `label`\n    - inferred data type\n    - visibility defaults\n    - optional validations (length, allowed values)\n    - mark layer_scope = "company" (Company Override layer, not Group Custom, unless Migration Approver chooses group-wide)\n\n- The Migration Approver can:\n\n  - Approve this new field for this company only.\n  - Approve it at group level (applies to all companies in this CompanyGroup).\n  - Reject it (column gets ignored or must be mapped manually to an existing field).\n\nWhen approved:\n\n- Update `EntityDefinition` in the CompanyGroup DB:\n\n  - Insert/modify definition_json for that entity to include this new field and mark it as `extra_data`-backed.\n\n- Version bump:\n\n  - `version = version + 1`\n  - `changed_by_user_id`\n  - `changed_at`\n  - layer_scope = "company" or "group" accordingly\n\n- Write AuditLog with `action_type=\"METADATA_CHANGE_FROM_IMPORT\"`.\n\nThis means after migration, the UI/forms/workflows in Phase 2+ will _see_ those new fields without code change.\n\n---\n\n## 3.4 Validation Rules Library\n\nPhase 3 must ship a validation layer with reusable rules, not hardcode in views.\n\nCategories:\n\n1. **Field-level rules**\n   Required, type, length/format, enum membership.\n\n2. **Cross-field rules**\n   Example:\n\n   - `due_date` must be >= `invoice_date`.\n   - `credit_limit` must be >= 0.\n   - For opening AR/AP, `total_amount` must match sum of line items (if you import line detail).\n\n3. **Reference rules**\n\n   - `warehouse_id` must exist in `Warehouse` table for that company.\n   - `customer_id` in AR import must either match existing or be created in the same batch.\n   - `chart_of_accounts.account_code` must not collide incorrectly with existing ones.\n\n4. **Business rules (Phase 2 tie-in)**\n\n   - For inventory start balances: cannot import negative stock unless explicitly allowed.\n   - For AR/AP open items: cannot import already-paid invoices.\n\nThese validations should:\n\n- Mark row as `invalid` with `hard` errors if must-block.\n- Mark row as `valid` but attach `soft` warnings (like “currency mismatch, will convert to company base currency”).\n\nThe UI should let Data Importer fix invalid rows and rerun validation without re-uploading.\n\n---\n\n## 3.5 Audit & Compliance in Phase 3\n\nEvery important action must hit AuditLog in that CompanyGroup DB with `company_id` and `user_id`:\n\n- Upload file → `IMPORT_UPLOAD`\n- Column mapping saved → `IMPORT_MAP_SAVED`\n- Metadata extension approved → `METADATA_CHANGE_FROM_IMPORT`\n- Validation completed → `IMPORT_VALIDATED`\n- Job submitted for approval → `IMPORT_SUBMIT_FOR_APPROVAL`\n- Approval / rejection → `IMPORT_APPROVED` or `IMPORT_REJECTED`\n- Commit → `IMPORT_COMMIT`\n- Rollback → `IMPORT_ROLLBACK`\n\nEach log entry should include:\n\n- Which role was active (from session),\n- Migration job ID,\n- Counts (rows valid / invalid / committed),\n- If GL postings were generated,\n- If metadata was modified.\n\nThis gives you a clean audit for UAT, external auditors, or finance leadership.\n\n---\n\n## 3.6 Company / CompanyGroup Scope Rules\n\nThe Data Migration Engine must obey the isolation model:\n\n1. **A migration_job belongs to exactly one `company_id`.**\n\n   - You cannot import for multiple companies in a single job.\n   - This keeps rollback simple and prevents cross-company leaks.\n\n2. The migration runs inside the CompanyGroup DB that holds that company.\n\n   - Staging tables, validation tables, commit logs all live in that CompanyGroup DB (e.g. `cg_garments`).\n   - This keeps everything auditable and backed up together with that company’s operations data.\n\n3. A Migration Approver with cross-company view (like Group CFO) may be able to approve imports for multiple companies in the same CompanyGroup, but:\n\n   - Each company’s job is still isolated.\n   - Each job’s GL postings and Inventory postings are posted to that specific `company_id`.\n\n4. Inter-company data can be imported, but:\n\n   - For inter-company opening balances, you still do one company at a time.\n   - If you need to import the mirrored opening balances for sister company B, that’s a second migration_job targeted at B.\n\nWe are **not** doing “one giant spreadsheet that seeds all companies at once” in Phase 3. That’s too risky for rollback and audit.\n\n---\n\n## 3.7 What Phase 3 Does Not Need Yet\n\nPhase 3 does **not** need to:\n\n- Import historical transactional journals for years of history (nice-to-have later, but cutover is usually “all open balances as of go-live date,” not full history).\n- Import historical workflow approvals.\n- Automatically reconcile inter-company balances across companies. (You can do that manually by importing AR to A and AP to B in coordinated jobs.)\n- Support PDF parsing / OCR / invoice scanning. That’s later, or AI phase.\n\nPhase 3 is focused on:\n\n- Masters,\n- Opening states,\n- Clean cutover,\n- Schema extension.\n\n---\n\n## 3.8 Phase 3 Deliverables (Engineering Checklist)\n\nWhen Phase 3 is complete, Twist ERP must ship all of the following:\n\n### 1. Migration Job Engine (in each CompanyGroup DB)\n\n- Tables:\n\n  - `migration_job`\n  - `migration_file`\n  - `migration_column_profile`\n  - `migration_field_mapping`\n  - `migration_staging_row`\n  - `migration_validation_error`\n  - `migration_commit_log`\n\n- CRUD + status transitions for these.\n\n### 2. File ingestion + profiling\n\n- Upload via UI/API.\n- Store file reference + hash.\n- Parse header and sample rows.\n- Infer column types.\n- Infer target entity (or confirm with user).\n\n### 3. Mapping UI / API\n\n- Let Data Importer map file columns to entity fields.\n- Auto-suggest matches.\n- Auto-suggest new fields (with proposed metadata JSON).\n- Save mapping to `migration_field_mapping`.\n\n### 4. Metadata extension hook\n\n- Migration Approver can approve new fields.\n- Engine updates `EntityDefinition` for that entity:\n\n  - Adds new field to Company Override layer (or Group layer if chosen).\n\n- Version bump and AuditLog entry with `METADATA_CHANGE_FROM_IMPORT`.\n\n### 5. Staging + normalization\n\n- Clean all rows into `migration_staging_row.clean_payload_json`.\n- Normalize datatypes, trim, map enums, resolve FK targets.\n- Mark each row `pending_validation`.\n\n### 6. Validation runner\n\n- Run validation rules.\n- Populate `migration_validation_error`.\n- Mark rows `valid` / `invalid` / `skipped`.`\n- Let Data Importer fix rows and rerun validation.\n- When all remaining rows are valid or skipped, mark job as `\"validated\"`.\n\n### 7. Approval workflow\n\n- Submit job for approval.\n- Trigger Workflow Engine with `MIGRATION_JOB.SUBMITTED_FOR_APPROVAL`.\n- Migration Approver can approve or reject.\n- Approval updates `migration_job.status=\"approved\"` and logs in AuditLog.\n\n### 8. Commit executor\n\n- For `status=\"approved\"`:\n\n  - Perform transactional import into live tables (Customer, Item, AR/AP opening, StockLedgerEntry, GLEntry).\n  - Apply posting rules for opening balances (Inventory, AR/AP, Equity).\n  - Write `migration_commit_log`.\n  - Mark job `status=\"committed\"`.\n  - Write AuditLog entries (`IMPORT_COMMIT` per impacted entity).\n\n### 9. Rollback executor\n\n- Allow rollback if safe:\n\n  - Check referential usage.\n  - Reverse or delete imported records.\n  - Reverse GL / stock postings.\n  - Update job `status=\"rolled_back\"`.\n  - Write AuditLog `IMPORT_ROLLBACK`.\n\n### 10. Security & audit integration\n\n- All actions require proper role (`Data Importer`, `Migration Approver`).\n- All actions run in the authenticated `active_company_id` context.\n- Every step writes an AuditLog entry into that CompanyGroup DB:\n\n  - `IMPORT_UPLOAD`\n  - `IMPORT_MAP_SAVED`\n  - `IMPORT_VALIDATED`\n  - `IMPORT_SUBMIT_FOR_APPROVAL`\n  - `IMPORT_APPROVED` or `IMPORT_REJECTED`\n  - `IMPORT_COMMIT`\n  - `IMPORT_ROLLBACK`\n  - `METADATA_CHANGE_FROM_IMPORT`\n\n### 11. UI/UX (minimum Phase 3 requirements)\n\nYou must provide at least basic admin-facing screens for:\n\n- Upload file(s) and start a migration job.\n- Column mapping (with suggestions).\n- Validation view (table of rows, with inline error list and inline edit).\n- Approval screen summarizing impact (counts, totals, new fields, GL impact).\n- Commit + Rollback status view.\n- History of past jobs for audit.\n\nIt doesn’t have to be pretty, but it has to be usable without going to the database manually.\n\n---\n\n## Phase 3 in one line\n\nPhase 3 turns Twist ERP into a self-service onboarding/migration machine:\n\n- You take any company’s old data,\n- The system learns its shape,\n- It extends the ERP data model if needed,\n- It validates, stages, and gets approval,\n- It imports cleanly with GL/stock impact,\n- It can roll back.\n\nThis makes Twist ERP “plug and play” for a new company, with almost zero developer involvement. This is what unlocks rollout at scale in Phases 8–10.\n"
  },
  {
    "title": "Phase0-1-README.md",
    "content": "# ERP Platform - Phase 0 & 1 Implementation Guide\n\n## 📋 Overview\n\nThis repository contains the implementation guide and starter files for **Phase 0 (Planning & Architecture)** and **Phase 1 (Platform Foundation)** of the Visual Drag-and-Drop ERP System.\n\n## 📦 Deliverables Included\n\n### Documentation (PDF)\n1. **Phase-0-Project-Planning-Guide.pdf** - Complete planning documentation\n2. **Phase-1-Platform-Foundation-Guide.pdf** - Technical implementation guide\n\n### Configuration Files\n3. **requirements.txt** - Python backend dependencies\n4. **package.json** - Frontend Node.js dependencies\n5. **initial_companies.json** - Database fixture for demo company\n6. **initial_permissions.json** - Database fixture for permissions\n7. **initial_roles.json** - Database fixture for roles\n\n## 🚀 Quick Start\n\n### Prerequisites\n\n- **Hardware:** \n  - CPU: Intel i9 / AMD Ryzen 9 (8+ cores)\n  - RAM: 64GB\n  - Storage: 2TB NVMe SSD\n  - GPU: NVIDIA RTX 4070+ (for AI)\n\n- **Software:**\n  - Ubuntu 22.04 LTS (recommended) or Windows 11 Pro\n  - Docker & Docker Compose\n  - Git\n  - Python 3.10+\n  - Node.js 18+\n  - PostgreSQL 15+ (will be embedded)\n\n### Installation Steps\n\n#### 1. Clone Repository (Future Step)\n```bash\ngit clone https://github.com/your-org/erp-platform.git\ncd erp-platform\n```\n\n#### 2. Backend Setup\n```bash\n# Create virtual environment\npython -m venv venv\nsource venv/bin/activate  # On Windows: venv\Scripts\activate\n\n# Install dependencies\npip install -r requirements.txt\n\n# Initialize embedded PostgreSQL\npython backend/embedded_db/init_db.py init\npython backend/embedded_db/init_db.py start\n\n# Run migrations\ncd backend\npython manage.py migrate\n\n# Load initial data\npython manage.py loaddata initial_companies.json\npython manage.py loaddata initial_permissions.json\npython manage.py loaddata initial_roles.json\n\n# Create superuser\npython manage.py createsuperuser\n\n# Start development server\npython manage.py runserver\n```\n\n#### 3. Frontend Setup\n```bash\ncd frontend\n\n# Install dependencies\nnpm install\n\n# Start development server\nnpm run dev\n```\n\n#### 4. Docker Setup (Alternative)\n```bash\n# Start all services\ndocker-compose up -d\n\n# Run migrations\ndocker-compose exec backend python manage.py migrate\n\n# Load fixtures\ndocker-compose exec backend python manage.py loaddata initial_companies.json\n\n# Create superuser\ndocker-compose exec backend python manage.py createsuperuser\n```\n\n## 📁 Project Structure\n\n```\nerp-platform/\n├── backend/\n│   ├── core/                      # Django settings\n│   ├── apps/\n│   │   ├── authentication/        # Auth module\n│   │   ├── companies/             # Multi-company\n│   │   ├── users/                 # User management\n│   │   ├── permissions/           # RBAC\n│   │   └── workflows/             # Workflow engine\n│   ├── shared/                    # Shared utilities\n│   ├── embedded_db/               # PostgreSQL management\n│   └── requirements.txt\n├── frontend/\n│   ├── src/\n│   │   ├── components/            # Reusable components\n│   │   ├── modules/               # Feature modules\n│   │   ├── services/              # API clients\n│   │   └── store/                 # State management\n│   └── package.json\n├── docs/\n│   ├── Phase-0-Project-Planning-Guide.pdf\n│   └── Phase-1-Platform-Foundation-Guide.pdf\n└── docker-compose.yml\n```\n\n## 🎯 Phase 0 Objectives\n\n- ✅ Define project scope and success criteria\n- ✅ Design multi-company architecture (Shared DB + Company ID)\n- ✅ Select technology stack\n- ✅ Create master timeline\n- ✅ Establish risk management framework\n\n**Duration:** 4–6 weeks\n\n## 🛠️ Phase 1 Objectives\n\n- ✅ Build modular plugin architecture\n- ✅ Implement multi-company data layer\n- ✅ Create authentication & authorization system\n- ✅ Set up embedded PostgreSQL\n- ✅ Establish API gateway and event bus\n- ✅ Build frontend foundation with company switcher\n\n**Duration:** 8–10 weeks\n\n## 🔑 Key Features Implemented\n\n### Multi-Company Support\n- Shared database with `company_id` filtering\n- Company hierarchy (parent-subsidiary)\n- Inter-company transactions support\n- Company-specific configurations\n- Consolidated reporting capability\n\n### Security\n- JWT-based authentication\n- Role-Based Access Control (RBAC)\n- Company-level data isolation\n- API gateway with request validation\n\n### Architecture\n- Modular Django apps\n- Event-driven communication (Redis pub/sub)\n- RESTful APIs with auto-documentation\n- React frontend with Redux state management\n\n## 📊 Success Metrics\n\n| Metric | Target | Status |\n|--------|--------|--------|\n| Code Coverage | ≥80% | To be measured |\n| API Response Time | <200ms | To be tested |\n| Multi-Company Isolation | 100% | Design complete |\n| Authentication | OAuth2 compliant | Planned |\n| Database Performance | <50ms queries | To be optimized |\n\n## 🧪 Testing\n\n```bash\n# Backend tests\ncd backend\npytest --cov=apps --cov-report=html\n\n# Frontend tests\ncd frontend\nnpm run test\n```\n\n## 📝 Next Steps\n\nAfter completing Phase 0 and 1:\n\n1. **Phase 2:** Implement MVP Business Modules (Finance, Inventory, Sales)\n2. **Phase 3:** Build Data Migration Engine\n3. **Phase 4:** Develop No-Code Builders & Workflows\n4. **Phase 5:** Integrate AI Companion (Rasa + Local LLM)\n\n## 🤝 Contributing\n\nFollow these guidelines:\n- Create feature branches from `main`\n- Write tests for all new code\n- Follow PEP 8 (Python) and Airbnb (JavaScript) style guides\n- Update documentation\n- Submit pull requests for review\n\n## 📖 Documentation\n\n- **Planning:** See `Phase-0-Project-Planning-Guide.pdf`\n- **Technical:** See `Phase-1-Platform-Foundation-Guide.pdf`\n- **API Docs:** Available at `/api/docs` (Swagger UI)\n\n## 🔒 Security\n\n- All sensitive data encrypted at rest\n- HTTPS enforced in production\n- Regular security audits planned\n- Row-level security (RLS) as backup layer\n\n## 📞 Support\n\nFor questions or issues:\n- Technical Lead: [Your Email]\n- Project Manager: [PM Email]\n- Documentation: `docs/` folder\n\n## 📄 License\n\nOpen Source - To be determined\n\n## 🎓 Training Resources\n\n- Django Best Practices\n- React Component Patterns\n- Multi-tenancy Design Patterns\n- PostgreSQL Performance Tuning\n\n---\n\n**Version:** 1.0  \n**Last Updated:** October 2025  \n**Status:** Phase 0-1 Implementation Ready\n"
  },
  {
    "title": "Phase2-3-README.md",
    "content": "# TWIST ERP - Phase 2 & 3 Implementation README\n\n## Project: TWIST ERP - Visual Drag-and-Drop Multi-Company ERP\n\n### Phase 2: MVP Business Modules\n### Phase 3: Intelligent Data Migration Engine\n\n---\n\n## 📦 Deliverables Overview\n\n### Phase 2 Documentation\n- **Phase-2-MVP-Modules-Guide.pdf** (21 pages)\n  - Complete Finance module (GL, AP, AR, Payments)\n  - Inventory & Warehouse management\n  - Sales & CRM with pipeline\n  - Procurement & Supplier management\n  - Inter-company transactions\n  - Testing strategies\n\n### Phase 3 Documentation\n- **Phase-3-Data-Migration-Guide.pdf** (24 pages)\n  - AI-powered field mapping engine\n  - Data profiling and quality assessment\n  - Validation and transformation\n  - Import engine with rollback\n  - Template system for reuse\n\n### Code Files Provided\n\n#### App Initialization Files\n1. `finance_init.py` - Finance module init\n2. `inventory_init.py` - Inventory module init\n3. `sales_init.py` - Sales module init\n4. `procurement_init.py` - Procurement module init\n5. `data_migration_init.py` - Data migration module init\n\n#### App Configuration Files\n6. `finance_apps.py` - Finance Django app config\n7. `inventory_apps.py` - Inventory Django app config\n8. `sales_apps.py` - Sales Django app config\n9. `procurement_apps.py` - Procurement Django app config\n10. `data_migration_apps.py` - Migration Django app config\n\n#### Serializers & API\n11. `finance_serializers.py` - Complete Finance REST API serializers\n\n#### Async Tasks\n12. `migration_tasks.py` - Celery tasks for data migration\n\n---\n\n## 🏗️ Phase 2: Module Architecture\n\n### Finance Module Components\n\n```\napps/finance/\n├── __init__.py\n├── apps.py\n├── models/\n│   ├── __init__.py\n│   ├── accounts.py          # Chart of Accounts\n│   ├── journal.py           # Journal Entry system\n│   ├── payables.py          # AR/AP invoices\n│   └── payments.py          # Payment processing\n├── serializers/\n│   ├── __init__.py\n│   └── finance_serializers.py\n├── views/\n│   ├── __init__.py\n│   ├── account_views.py\n│   ├── invoice_views.py\n│   └── payment_views.py\n├── services/\n│   ├── __init__.py\n│   ├── accounting_engine.py # Auto journal posting\n│   └── reconciliation.py    # Bank reconciliation\n├── signals.py               # Post-save hooks\n├── urls.py\n└── tests/\n    ├── test_accounts.py\n    ├── test_journals.py\n    └── test_invoices.py\n```\n\n### Key Features - Finance\n- **Double-entry bookkeeping** with automatic balancing\n- **Multi-currency** support with exchange rates\n- **Hierarchical chart of accounts**\n- **AR/AP management** with aging reports\n- **Payment processing** with allocation\n- **Budget controls** integrated with procurement\n- **Inter-company elimination** for consolidation\n\n### Inventory Module Components\n\n```\napps/inventory/\n├── __init__.py\n├── apps.py\n├── models/\n│   ├── __init__.py\n│   ├── product.py           # Product master\n│   ├── warehouse.py         # Warehouse & stock ledger\n│   └── movement.py          # Stock movements\n├── serializers/\n│   └── inventory_serializers.py\n├── views/\n│   ├── product_views.py\n│   ├── warehouse_views.py\n│   └── movement_views.py\n├── services/\n│   ├── stock_engine.py      # Stock calculation\n│   ├── valuation.py         # FIFO/LIFO valuation\n│   └── reorder.py           # Auto reorder alerts\n└── tests/\n```\n\n### Key Features - Inventory\n- **Double-entry stock ledger** (immutable transaction log)\n- **Multi-warehouse** with location tracking\n- **Batch and serial number** tracking\n- **Valuation methods** (FIFO, LIFO, Weighted Average)\n- **Reorder automation** with AI predictions\n- **IoT sensor integration** for real-time updates\n\n### Sales & Procurement Modules\n\nSimilar structure with:\n- Customer/Supplier masters\n- Order management (Sales Order, Purchase Order)\n- Delivery tracking\n- Invoice generation automation\n- Integration with Finance and Inventory\n\n---\n\n## 🤖 Phase 3: Data Migration Architecture\n\n### Migration Pipeline Flow\n\n```\nUpload File → Profile Data → AI Match Fields → User Review →\nValidate → Transform → Import → Audit\n```\n\n### AI Field Matcher Components\n\n#### Matching Strategies (Weighted)\n1. **Exact Match** (40%) - Normalized name matching\n2. **Fuzzy Match** (25%) - String similarity (Levenshtein)\n3. **Semantic Match** (25%) - Keyword extraction and comparison\n4. **Type Match** (10%) - Data type compatibility\n\n#### Confidence Scoring\n- **≥ 80%**: Auto-accept (green)\n- **60-79%**: Review suggested (yellow)\n- **< 60%**: Manual required (red)\n\n### Data Profiler Features\n\n```python\n# For each column analyzes:\n- Data type detection\n- Null/missing value percentage\n- Unique value count\n- Statistical distribution (numeric)\n- Sample values\n- Data quality issues\n```\n\n### Validation Engine\n\n**Built-in Rules:**\n- Required field checking\n- Data type validation\n- Format validation (email, phone, dates)\n- Range validation (min/max)\n- Foreign key reference checks\n- Duplicate detection\n\n**Custom Rules:**\n- Business logic validation\n- Cross-field validation\n- Company-specific rules\n\n### Transformation Engine\n\n**Supported Transformations:**\n- Trim whitespace\n- Case conversion (upper/lower/title)\n- Date format standardization\n- Phone number normalization\n- Find & replace\n- Value mapping (e.g., "Y" → true)\n- Calculated fields\n- Default values for nulls\n\n---\n\n## 🚀 Installation & Setup\n\n### 1. Install Dependencies\n\n```bash\n# Backend - Add to requirements.txt\npandas==2.1.4\nopenpyxl==3.1.2\nxlrd==2.0.1\nscikit-learn==1.3.2\nfuzzywuzzy==0.18.0\npython-Levenshtein==0.23.0\nsentence-transformers==2.2.2\npydantic==2.5.3\ncelery==5.3.4\nredis==5.0.1\n```\n\n### 2. Create Apps Structure\n\n```bash\ncd backend/apps\n\n# Create Phase 2 apps\nmkdir -p finance/{models,serializers,views,services,tests}\nmkdir -p inventory/{models,serializers,views,services,tests}\nmkdir -p sales/{models,serializers,views,services,tests}\nmkdir -p procurement/{models,serializers,views,services,tests}\n\n# Create Phase 3 app\nmkdir -p data_migration/{models,serializers,views,services,tasks,tests}\n\n# Copy init files\ncp finance_init.py finance/__init__.py\ncp finance_apps.py finance/apps.py\n# Repeat for other modules...\n```\n\n### 3. Configure Django Settings\n\n```python\n# backend/core/settings.py\n\nINSTALLED_APPS = [\n    # ... existing apps\n    'apps.finance',\n    'apps.inventory',\n    'apps.sales',\n    'apps.procurement',\n    'apps.data_migration',\n]\n\n# Celery Configuration\nCELERY_BROKER_URL = 'redis://localhost:6379/0'\nCELERY_RESULT_BACKEND = 'redis://localhost:6379/0'\nCELERY_ACCEPT_CONTENT = ['json']\nCELERY_TASK_SERIALIZER = 'json'\nCELERY_RESULT_SERIALIZER = 'json'\n\n# File Upload Settings\nMEDIA_ROOT = os.path.join(BASE_DIR, 'media')\nMEDIA_URL = '/media/'\nMAX_UPLOAD_SIZE = 104857600  # 100MB\n```\n\n### 4. Run Migrations\n\n```bash\npython manage.py makemigrations finance inventory sales procurement data_migration\npython manage.py migrate\n```\n\n### 5. Start Celery Worker\n\n```bash\n# Terminal 1: Start Redis\nredis-server\n\n# Terminal 2: Start Celery worker\ncelery -A core worker -l info\n\n# Terminal 3: Start Django\npython manage.py runserver\n```\n\n---\n\n## 📊 Testing Strategy\n\n### Unit Tests\n\n```bash\n# Test Finance module\npytest apps/finance/tests/test_accounts.py -v\n\n# Test Data Migration\npytest apps/data_migration/tests/test_field_matcher.py -v\n\n# Coverage report\npytest --cov=apps --cov-report=html\n```\n\n### Integration Tests\n\n```python\n# Example: End-to-end Order-to-Cash test\ndef test_order_to_cash_flow():\n    # 1. Create Sales Order\n    order = create_sales_order()\n    \n    # 2. Deliver goods (updates inventory)\n    delivery = process_delivery(order)\n    \n    # 3. Generate invoice (creates AR)\n    invoice = create_invoice_from_order(order)\n    \n    # 4. Record payment\n    payment = record_customer_payment(invoice)\n    \n    # 5. Verify GL entries\n    assert_journal_entries_balanced()\n```\n\n### Performance Tests\n\n```bash\n# Load test data migration with 50K rows\npython manage.py test_migration_performance --rows=50000\n\n# Benchmark API endpoints\nlocust -f locustfile.py --host=http://localhost:8000\n```\n\n---\n\n## 📈 Implementation Timeline\n\n### Phase 2 (10-12 weeks)\n\n**Weeks 1-3: Finance**\n- Week 1: Chart of Accounts, Journal system\n- Week 2: AR/AP invoices\n- Week 3: Payments, testing\n\n**Weeks 4-6: Inventory**\n- Week 4: Product master, Warehouse\n- Week 5: Stock ledger, Movements\n- Week 6: Valuation, testing\n\n**Weeks 7-9: Sales & Procurement**\n- Week 7: Customer/Supplier, Orders\n- Week 8: Delivery/Receipt workflows\n- Week 9: Integration, testing\n\n**Weeks 10-12: Integration**\n- Week 10: Inter-company transactions\n- Week 11: Consolidated reporting\n- Week 12: End-to-end testing, optimization\n\n### Phase 3 (6-8 weeks)\n\n**Weeks 1-2: Foundation**\n- Migration models\n- File upload handling\n- Data profiling service\n\n**Weeks 3-4: AI Matching**\n- Field matcher algorithm\n- Confidence scoring\n- Alternative suggestions\n\n**Weeks 5-6: Validation & Transform**\n- Validation engine\n- Transformation rules\n- Data cleansing\n\n**Weeks 7-8: Import & UI**\n- Import engine with rollback\n- Drag-and-drop mapping UI\n- Progress tracking\n- End-to-end testing\n\n---\n\n## 🎯 Success Metrics\n\n### Phase 2\n- ☑️ Complete O2C flow functional\n- ☑️ Complete P2P flow functional\n- ☑️ Real-time inventory updates\n- ☑️ Multi-company consolidation\n- ☑️ 90%+ test coverage\n- ☑️ API response < 300ms\n\n### Phase 3\n- ☑️ 90%+ auto-mapping accuracy\n- ☑️ 70% reduction in migration time\n- ☑️ Zero data loss\n- ☑️ Support 100K rows\n- ☑️ Template reuse working\n- ☑️ Full audit trail\n\n---\n\n## 🔗 API Endpoints (Phase 2)\n\n### Finance APIs\n\n```\nGET    /api/v1/finance/accounts/              # List accounts\nPOST   /api/v1/finance/accounts/              # Create account\nGET    /api/v1/finance/accounts/{id}/         # Get account\nGET    /api/v1/finance/accounts/{id}/balance/ # Get balance\nGET    /api/v1/finance/accounts/{id}/transactions/ # Transactions\n\nPOST   /api/v1/finance/journal-vouchers/      # Create voucher\nGET    /api/v1/finance/journal-vouchers/      # List vouchers\nPOST   /api/v1/finance/journal-vouchers/{id}/post/ # Post voucher\n\nPOST   /api/v1/finance/invoices/              # Create invoice\nGET    /api/v1/finance/invoices/              # List invoices\nGET    /api/v1/finance/invoices/overdue/      # Overdue invoices\n\nPOST   /api/v1/finance/payments/              # Record payment\nGET    /api/v1/finance/payments/              # List payments\n```\n\n### Data Migration APIs\n\n```\nPOST   /api/v1/migration/sessions/            # Create session\nPOST   /api/v1/migration/sessions/{id}/upload/ # Upload file\nGET    /api/v1/migration/sessions/{id}/profile/ # Get profile\nPOST   /api/v1/migration/sessions/{id}/mapping/ # Save mapping\nPOST   /api/v1/migration/sessions/{id}/validate/ # Validate\nPOST   /api/v1/migration/sessions/{id}/import/ # Start import\nGET    /api/v1/migration/sessions/{id}/status/ # Check status\nPOST   /api/v1/migration/sessions/{id}/rollback/ # Rollback\n\nGET    /api/v1/migration/templates/           # List templates\nPOST   /api/v1/migration/templates/           # Create template\n```\n\n---\n\n## 🐛 Common Issues & Solutions\n\n### Issue: Import fails with "company not found"\n**Solution:** Ensure company context is set via middleware or explicitly\n\n### Issue: AI matching gives low confidence\n**Solution:** \n- Check column names are descriptive\n- Add aliases to target schema\n- Use template from similar previous import\n\n### Issue: Stock balance incorrect\n**Solution:** Run stock reconciliation service\n\n### Issue: Journal entries don't balance\n**Solution:** Validation prevents this; check custom journal logic\n\n---\n\n## 📚 Next Steps\n\nAfter completing Phase 2 & 3:\n\n1. **Phase 4:** No-Code Form & Module Builders\n2. **Phase 5:** AI Companion Integration (Rasa + LLM)\n3. **Phase 6:** Advanced Modules (HR, Assets, Projects)\n4. **Phase 7:** UAT and Training\n5. **Phase 8:** Pilot Deployment\n\n---\n\n## 🤝 Support & Resources\n\n- **Documentation:** See PDF guides in `docs/` folder\n- **Code Examples:** Complete models in PDF guides\n- **API Docs:** Available at `/api/docs/` (Swagger)\n- **Test Data:** Sample imports in `fixtures/` folder\n\n---\n\n**Version:** 1.0  \n**Last Updated:** October 2025  \n**Status:** Phase 2-3 Ready for Implementation\n**Project:** TWIST ERP\n"
  }
]