# Enhanced Django Views for Report Builder
# This adds all the Flask functionality to your existing Django views

from collections import deque
import json
import logging
import pandas as pd
import numpy as np
from datetime import datetime
import csv
from django.contrib.auth.decorators import login_required
from django.http import JsonResponse, HttpResponse
from django.shortcuts import redirect, render, get_object_or_404
from django.views.decorators.http import require_http_methods, require_POST
from django.views.decorators.csrf import csrf_exempt
from django.core.paginator import Paginator
from django.utils import timezone
from django.contrib import messages
from django.contrib.auth import get_user_model
from django.db.models import Q
from sqlalchemy import inspect
from .models import ExternalConnection, SavedReport, ConnectionJoin, ReportShare
from .services.report_builder import ReportBuilderService
from .utils import get_external_engine, log_user_action
from .transformation_engine import TransformationEngine
from django.template.loader import render_to_string
from sqlalchemy import table, column, select, func
from sqlalchemy.sql.sqltypes import Integer, Numeric, Float, BigInteger, SmallInteger, DECIMAL

import pdb


logger = logging.getLogger(__name__)

def _is_numeric_sqla_type(sqla_type):
    """Helper to check if a SQLAlchemy type is numeric."""
    try:
        return isinstance(sqla_type, (Integer, Numeric, Float, BigInteger, SmallInteger, DECIMAL))
    except Exception:
        return False

# ================================================================
# REPORT BUILDER VIEWS
# ================================================================

@login_required
def report_builder_view(request):
    """Enhanced Report Builder page with full Flask functionality"""
    try:
        connections = ExternalConnection.objects.filter(owner=request.user).order_by('nickname')
        recent_reports = SavedReport.objects.filter(owner=request.user).order_by('-updated_at')[:10]
        
        # Fetch all joins for all of the user's connections
        all_joins = {}
        for conn in connections:
            joins = ConnectionJoin.objects.filter(connection=conn)
            all_joins[str(conn.id)] = list(joins.values('left_table', 'left_column', 'right_table', 'right_column', 'join_type'))

        context = {
            'connections': connections,
            'recent_reports': recent_reports,
            'user_can_create': True,
            'user_can_share': hasattr(request.user, 'user_type') and request.user.user_type in ['Admin', 'Moderator'],
            'full_width_page': True,  # Match Flask template
            'all_joins_json': json.dumps(all_joins)
        }
        
        return render(request, 'report_builder.html', context)
    except Exception as e:
        logger.error(f"Error loading report builder: {e}")
        messages.error(request, "Failed to load report builder")
        return redirect('mis_app:home')

@login_required
@require_POST
def profile_data_api(request):
    """
    Takes a report config, executes a limited query to get a data preview,
    and returns it along with column profiling information.
    """
    try:
        report_config = json.loads(request.body)
        
        # We want a preview, so we'll limit the query to 500 rows
        preview_config = report_config.copy()
        preview_config['page'] = 1
        preview_config['page_size'] = 500

        service = ReportBuilderService()
        df, total_rows, error = service.build_advanced_report(preview_config, request.user)

        if error:
            return JsonResponse({'success': False, 'error': error}, status=400)

        if df is None or df.empty:
            return JsonResponse({
                'success': True,
                'preview_data': [],
                'column_metadata': {},
                'message': 'No data returned for this configuration.'
            })

        # Profile the resulting dataframe
        transformer = TransformationEngine(df)
        column_metadata = {}
        for col_name in df.columns:
            # Use the existing profiling logic in TransformationEngine
            profile = transformer.get_column_profile(col_name)
            if profile:
                # Add inferred type for easier frontend logic
                profile['inferred_type'] = 'numeric' if df[col_name].dtype in ['int64', 'float64'] else 'text'
                column_metadata[col_name] = profile

        # Convert DataFrame to JSON-safe format
        df_safe = df.replace({pd.NaT: None, np.nan: None})
        preview_data = df_safe.to_dict('records')

        return JsonResponse({
            'success': True,
            'preview_data': preview_data,
            'column_metadata': column_metadata,
        })

    except json.JSONDecodeError:
        return JsonResponse({'success': False, 'error': 'Invalid JSON format.'}, status=400)
    except Exception as e:
        logger.error(f"Error profiling data: {e}", exc_info=True)
        return JsonResponse({'success': False, 'error': str(e)}, status=500)
    
@login_required
def data_prep_modal_content(request):
    """
    A simple view that just renders and returns the HTML content for the
    data preparation modal.
    """
    return render(request, 'modals/data_prep_modal_content.html')
    
# ================================================================
# REPORT API ENDPOINTS - MATCHING FLASK FUNCTIONALITY
# ================================================================

@login_required
@require_POST
def build_report_api(request):
    """Main report building API - matches Flask /api/build_report"""
    try:
        data = json.loads(request.body)
        report_config = data
        
        # Validate connection access
        connection_id = report_config.get('connection_id')
        if not connection_id:
            return JsonResponse({'error': 'Connection ID is required'}, status=400)

        try:
            connection = ExternalConnection.objects.get(id=connection_id, owner=request.user)
        except ExternalConnection.DoesNotExist:
            return JsonResponse({'error': 'Connection not found or access denied'}, status=403)

        # Use service to build report
        service = ReportBuilderService()
        df, total_rows, error = service.build_advanced_report(report_config, request.user)

        if error:
            return JsonResponse({'error': error}, status=400)

        if df is None or df.empty:
            return JsonResponse({
                'success': True,
                'data': {'headers': [], 'rows': []},
                'total_rows': 0,
                'message': 'No data returned for the specified criteria'
            })

        # Convert DataFrame to JSON-safe format
        df_safe = df.replace({pd.NaT: None, pd.NA: None, np.nan: None})
        df_safe = df_safe.where(pd.notnull(df_safe), None)
        
        headers = list(df_safe.columns)
        rows = df_safe.to_dict('records')

        # Calculate total pages
        page = report_config.get('page', 1)
        page_size = report_config.get('page_size', 100)
        total_pages = (total_rows + page_size - 1) // page_size if page_size > 0 else 0

        return JsonResponse({
            'success': True,
            'data': {'headers': headers, 'rows': rows},
            'total_rows': total_rows,
            'pagination': {
                'current_page': page,
                'page_size': page_size,
                'total_pages': total_pages,
            }
        })

        # Log report execution
        try:
            log_user_action(
                request.user,
                'execute_report',
                'report',
                f"report_{timezone.now().strftime('%Y%m%d_%H%M%S')}",
                f"Report executed with {total_rows} rows",
                {
                    'connection_id': str(connection.id),
                    'connection_name': connection.nickname,
                    'row_count': total_rows,
                    'columns_count': len(report_config.get('columns', [])),
                    'filters_count': len(report_config.get('filters', [])),
                    'has_groups': bool(report_config.get('groups', [])),
                }
            )
        except Exception as log_error:
            logger.warning(f"Failed to log report execution: {log_error}")

        return JsonResponse({
            'success': True,
            'data': {'headers': headers, 'rows': rows},
            'total_rows': total_rows,
            'current_page': report_config.get('page', 1),
            'execution_time': timezone.now().isoformat()
        })

    except json.JSONDecodeError:
        return JsonResponse({'error': 'Invalid JSON in request body'}, status=400)
    except Exception as e:
        logger.error(f"Error building report: {e}", exc_info=True)
        return JsonResponse({'error': f'Report execution failed: {str(e)}'}, status=500)

@login_required
def get_connections_api(request):
    """Get database connections - matches Flask /api/get_db_connections"""
    try:
        connections = ExternalConnection.objects.filter(owner=request.user).order_by('nickname')
        
        connections_data = []
        for conn in connections:
            # Check connection status (simplified)
            engine = get_external_engine(conn.id, request.user)
            connected = engine is not None
            
            connections_data.append({
                "id": str(conn.id),
                "nickname": conn.nickname,
                "db_type": conn.db_type,
                "host": conn.host,
                "port": conn.port,
                "db_name": conn.db_name,
                "filepath": conn.filepath,
                "is_default": conn.is_default,
                "connected": connected
            })
        
        return JsonResponse(connections_data, safe=False)
    except Exception as e:
        logger.error(f"Error fetching connections: {e}")
        return JsonResponse({'error': str(e)}, status=500)

@login_required
def get_tables_api(request):
    """Get visible tables for connection - matches Flask /api/get_tables"""
    connection_id = request.GET.get('connection_id')
    
    try:
        if not connection_id:
            return JsonResponse({'tables': [], 'error': 'Connection ID required'})

        connection = get_object_or_404(ExternalConnection, id=connection_id, owner=request.user)
        engine = get_external_engine(connection_id, request.user)
        
        if not engine:
            return JsonResponse({'tables': [], 'error': 'Database connection failed'})

        inspector = inspect(engine)
        schema = connection.schema if connection.db_type == 'postgresql' else None
        all_tables = inspector.get_table_names(schema=schema)
        
        # Filter hidden tables
        hidden_tables = set(filter(None, (connection.hidden_tables or '').split(',')))
        visible_tables = sorted([tbl for tbl in all_tables if tbl not in hidden_tables])
        
        return JsonResponse({'tables': visible_tables})
        
    except Exception as e:
        logger.error(f"Error getting tables: {e}")
        return JsonResponse({'tables': [], 'error': str(e)})

@login_required
def get_columns_for_tables_api(request):
    """Get columns for multiple tables - matches Flask /api/get_columns_for_tables"""
    if request.method != 'POST':
        return JsonResponse({'columns': [], 'error': 'POST method required'})
    
    try:
        data = json.loads(request.body)
        connection_id = data.get('connection_id')
        tables_to_query = data.get('tables', [])
        
        if not connection_id:
            return JsonResponse({'columns': [], 'error': 'Connection ID required'})

        connection = get_object_or_404(ExternalConnection, id=connection_id, owner=request.user)
        engine = get_external_engine(connection_id, request.user)
        
        if not engine:
            return JsonResponse({'columns': [], 'error': 'Database connection failed'})

        inspector = inspect(engine)
        all_columns = []

        for table_name in tables_to_query:
            try:
                columns = inspector.get_columns(table_name)
                for col in columns:
                    all_columns.append({
                        "fullName": f"{table_name}.{col['name']}",
                        "name": col['name'],
                        "source": table_name,
                        "type": str(col['type']),
                        "is_numeric": _is_numeric_type(col['type'])
                    })
            except Exception as e:
                logger.warning(f"Could not get columns for table {table_name}: {e}")

        return JsonResponse({'columns': all_columns})
        
    except json.JSONDecodeError:
        return JsonResponse({'columns': [], 'error': 'Invalid JSON'})
    except Exception as e:
        logger.error(f"Error getting columns: {e}")
        return JsonResponse({'columns': [], 'error': str(e)})

@login_required
@login_required
def get_my_reports_api(request):
    """Get user's reports, including those owned and those shared with them."""
    try:
        user = request.user
        
        # Reports shared with the current user
        shared_report_ids = ReportShare.objects.filter(shared_with=user).values_list('report_id', flat=True)
        
        # Combine owned reports and shared reports
        reports = SavedReport.objects.filter(
            Q(owner=user) | Q(id__in=shared_report_ids)
        ).distinct().order_by('-updated_at')
        
        # Get permissions for shared reports
        shares = ReportShare.objects.filter(shared_with=user, report__in=reports).values('report_id', 'permission')
        permissions = {str(share['report_id']): share['permission'] for share in shares}

        data = []
        for report in reports:
            if report.owner == user:
                permission = 'owner'
            else:
                permission = permissions.get(str(report.id), 'view') # Default to 'view' if something is wrong

            data.append({
                'id': str(report.id),
                'name': report.report_name,
                'owner': report.owner.username,
                'permission': permission,
                'updated_at': report.updated_at.strftime('%Y-%m-%d %H:%M'),
            })

        return JsonResponse({'success': True, 'reports': data})
    except Exception as e:
        logger.error(f"Error in get_my_reports_api: {e}", exc_info=True)
        return JsonResponse({'success': False, 'error': str(e)}, status=500)


# ADD THE FOLLOWING THREE NEW VIEWS TO THE END OF THE FILE

@login_required
def list_users_api(request):
    """Returns a list of all users, excluding the current user."""
    User = get_user_model()
    # Exclude current user and superusers if desired
    users = User.objects.exclude(id=request.user.id).exclude(is_superuser=True).values('id', 'username')
    return JsonResponse({'success': True, 'users': list(users)})

@login_required
def get_report_shares_api(request, report_id):
    """Gets the current sharing settings for a report."""
    report = get_object_or_404(SavedReport, id=report_id, owner=request.user)
    shares = ReportShare.objects.filter(report=report)
    data = [{
        'user_id': share.shared_with.id,
        'username': share.shared_with.username,
        'permission': share.permission
    } for share in shares]
    return JsonResponse({'success': True, 'shares': data})

@login_required
@require_POST
def update_report_shares_api(request, report_id):
    """Updates the sharing settings for a report."""
    report = get_object_or_404(SavedReport, id=report_id, owner=request.user)
    data = json.loads(request.body)
    shares_data = data.get('shares', [])

    # Delete existing shares for this report
    ReportShare.objects.filter(report=report).delete()

    User = get_user_model()
    new_shares = []
    for share_info in shares_data:
        try:
            user_to_share_with = User.objects.get(id=share_info.get('user_id'))
            new_shares.append(
                ReportShare(
                    report=report,
                    shared_with=user_to_share_with,
                    permission=share_info.get('permission', 'view'),
                    shared_by=request.user
                )
            )
        except User.DoesNotExist:
            continue # Skip if user doesn't exist

    # Bulk create new shares
    ReportShare.objects.bulk_create(new_shares)
    return JsonResponse({'success': True, 'message': 'Sharing settings updated.'})

@login_required
@require_POST
def save_report_api(request):
    """Save new report - matches Flask /api/save_report"""
    try:
        data = json.loads(request.body)
        report_name = data.get('report_name', '').strip()
        report_config = data.get('report_config', {})
        description = data.get('description', '').strip()

        if not report_name:
            return JsonResponse({
                'success': False,
                'error': 'Report name is required'
            }, status=400)

        if not report_config:
            return JsonResponse({
                'success': False,
                'error': 'Report configuration is required'
            }, status=400)

        # Validate report configuration
        service = ReportBuilderService()
        validation = service.validate_report_config(report_config)
        if not validation['valid']:
            return JsonResponse({
                'success': False,
                'error': 'Invalid report configuration',
                'validation_errors': validation['errors']
            }, status=400)

        # Check for duplicate names
        if SavedReport.objects.filter(owner=request.user, report_name=report_name).exists():
            return JsonResponse({
                'success': False,
                'error': f'A report named "{report_name}" already exists'
            }, status=409)

        # Create new report
        new_report = SavedReport.objects.create(
            owner=request.user,
            report_name=report_name,
            report_config=report_config,
            description=description
        )

        # Log the action
        try:
            log_user_action(
                request.user,
                'save_report',
                'report',
                str(new_report.id),
                f"Report '{report_name}' saved",
                {
                    'report_id': str(new_report.id),
                    'report_name': report_name,
                    'has_calculated_fields': bool(report_config.get('calculated_fields', [])),
                    'columns_count': len(report_config.get('columns', [])),
                }
            )
        except Exception as log_error:
            logger.warning(f"Failed to log report save: {log_error}")

        return JsonResponse({
            'success': True,
            'report_id': str(new_report.id),
            'message': f'Report "{report_name}" saved successfully',
            'warnings': validation.get('warnings', [])
        })

    except json.JSONDecodeError:
        return JsonResponse({'success': False, 'error': 'Invalid JSON in request body'}, status=400)
    except Exception as e:
        logger.error(f"Error saving report: {e}")
        return JsonResponse({'success': False, 'error': str(e)}, status=500)

@login_required
def get_report_config_api(request, report_id):
    """Get report configuration - matches Flask /api/get_report_config/<report_id>"""
    try:
        report = get_object_or_404(SavedReport, id=report_id, owner=request.user)
        
        return JsonResponse({
            'success': True,
            'config': report.report_config,
            'pivot_config': getattr(report, 'pivot_config', {}),
            'name': report.report_name,
            'permission': 'edit'  # User owns the report
        })
        
    except SavedReport.DoesNotExist:
        return JsonResponse({'success': False, 'error': 'Report not found'}, status=404)
    except Exception as e:
        logger.error(f"Error getting report config: {e}")
        return JsonResponse({'success': False, 'error': str(e)}, status=500)

@login_required
@require_POST
def update_report_api(request, report_id):
    """Update existing report - matches Flask update functionality"""
    try:
        data = json.loads(request.body)
        report_config = data.get('report_config')
        report_name = data.get('report_name')

        report = get_object_or_404(SavedReport, id=report_id, owner=request.user)
        
        if report_name:
            report.report_name = report_name.strip()
        
        if report_config:
            report.report_config = report_config

        report.save()

        return JsonResponse({
            'success': True,
            'message': f'Report "{report.report_name}" updated successfully'
        })
    except Exception as e:
        logger.error(f"Error updating report {report_id}: {e}", exc_info=True)
        return JsonResponse({'success': False, 'error': str(e)}, status=500)

@login_required
@require_POST
def check_join_path_api(request):
    """
    Enhanced join path checking that properly uses data model joins.
    """
    try:
        data = json.loads(request.body)
        connection_id = data.get('connection_id')
        tables = data.get('tables', [])

        if not connection_id or len(tables) < 2:
            return JsonResponse({'success': True, 'path_exists': True, 'message': 'No join needed'})

        # Get connection and validate access
        connection = get_object_or_404(ExternalConnection, id=connection_id, owner=request.user)
        
        # Get all saved joins for this connection
        saved_joins = ConnectionJoin.objects.filter(connection=connection)
        
        # Build the graph properly
        graph = {}
        for join in saved_joins:
            try:
                left_table = join.left_table
                right_table = join.right_table
                
                # Add bidirectional connection
                if left_table not in graph:
                    graph[left_table] = []
                if right_table not in graph:
                    graph[right_table] = []
                    
                graph[left_table].append(right_table)
                graph[right_table].append(left_table)
            except Exception as e:
                logger.warning(f"Invalid join skipped: {e}")
                continue

        # Check connectivity using BFS
        if not graph:
            return JsonResponse({
                'success': True, 
                'path_exists': False,
                'message': 'No joins defined in data model'
            })

        # Start BFS from first table
        visited = set()
        queue = deque([tables[0]])
        
        while queue:
            current_table = queue.popleft()
            if current_table in visited:
                continue
                
            visited.add(current_table)
            
            # Add all connected tables to queue
            for neighbor in graph.get(current_table, []):
                if neighbor not in visited:
                    queue.append(neighbor)

        # Check if all required tables are connected
        path_exists = all(table in visited for table in tables)
        
        return JsonResponse({
            'success': True,
            'path_exists': path_exists,
            'message': f'Path found for {len(visited)} of {len(tables)} tables' if path_exists else 'No path found'
        })

    except Exception as e:
        logger.error(f"Error checking join path: {e}", exc_info=True)
        return JsonResponse({'success': False, 'error': str(e)}, status=500)

@login_required
@require_POST  
def export_report_excel_api(request):
    """Export report to Excel - matches Flask export functionality"""
    try:
        data = json.loads(request.body)
        # --- FIX: Read headers and rows from the top level of the request data ---
        headers = data.get('headers', [])
        rows = data.get('rows', [])
        report_config = data.get('report_config', {})
        
        if not headers or not rows:
            return JsonResponse({'success': False, 'error': 'No data to export'}, status=400)

        # Create DataFrame
        df = pd.DataFrame(rows)
        
        # Generate filename
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_name = report_config.get('name', 'report')
        safe_name = "".join(c for c in report_name if c.isalnum() or c in (' ', '-', '_')).rstrip()
        filename = f"{safe_name}_{timestamp}.xlsx"

        # Create Excel response
        response = HttpResponse(
            content_type='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
        )
        response['Content-Disposition'] = f'attachment; filename="{filename}"'

        with pd.ExcelWriter(response, engine='openpyxl') as writer:
            df.to_excel(writer, sheet_name='Report Data', index=False)
            
            # Add metadata sheet
            metadata = pd.DataFrame([
                ['Export Date', datetime.now().strftime('%Y-%m-%d %H:%M:%S')],
                ['User', request.user.username],
                ['Total Rows', len(rows)],
                ['Columns', len(headers)],
                ['Filters Applied', len(report_config.get('filters', []))],
                ['Groups Applied', len(report_config.get('groups', []))],
            ], columns=['Property', 'Value'])
            metadata.to_excel(writer, sheet_name='Metadata', index=False)

        # Log export action
        try:
            log_user_action(
                request.user,
                'export_report',
                'report',
                f'export_{timestamp}',
                'Report exported as Excel',
                {'format': 'excel', 'row_count': len(rows), 'filename': filename}
            )
        except Exception as log_error:
            logger.warning(f"Failed to log export action: {log_error}")

        return response

    except Exception as e:
        logger.error(f"Error exporting to Excel: {e}")
        return JsonResponse({'success': False, 'error': str(e)}, status=500)

@login_required
@require_POST
def get_filter_values_api(request):
    """
    Gets distinct values for a list of fields, to be used in dynamic filters.
    """
    try:
        data = json.loads(request.body)
        connection_id = data.get('connection_id')
        fields = data.get('fields', [])

        if not connection_id or not fields:
            return JsonResponse({'success': False, 'error': 'Connection ID and fields are required.'}, status=400)

        engine = get_external_engine(connection_id, request.user)
        if not engine:
            return JsonResponse({'success': False, 'error': 'Database connection failed.'}, status=500)

        results = {}
        with engine.connect() as conn:
            for field_name in fields:
                try:
                    table_name, column_name = field_name.split('.')
                    tbl = table(table_name, column(column_name))
                    
                    # Check if column is numeric for min/max
                    inspector = inspect(engine)
                    columns = inspector.get_columns(table_name)
                    col_info = next((c for c in columns if c['name'] == column_name), None)
                    is_numeric = False
                    if col_info:
                        is_numeric = _is_numeric_sqla_type(col_info['type'])

                    if is_numeric:
                        # For numeric columns, get min and max
                        query = select(func.min(tbl.c[column_name]), func.max(tbl.c[column_name]))
                        min_val, max_val = conn.execute(query).first()
                        results[field_name] = {'min': min_val, 'max': max_val}
                    else:
                        # For other columns, get distinct values
                        query = select(tbl.c[column_name]).distinct().limit(100) # Limit to 100 distinct values
                        distinct_values = [row[0] for row in conn.execute(query)]
                        results[field_name] = {'values': distinct_values}
                except Exception as e:
                    logger.warning(f"Could not get filter values for {field_name}: {e}")
                    results[field_name] = {'error': str(e)}

        return JsonResponse({'success': True, 'data': results})

    except Exception as e:
        logger.error(f"Error getting filter values: {e}", exc_info=True)
        return JsonResponse({'success': False, 'error': str(e)}, status=500)


@login_required
@require_POST
def find_joins_api(request):
    """
    Finds and returns the necessary joins to connect a given list of tables
    using a spanning tree algorithm.
    """
    try:
        data = json.loads(request.body)
        connection_id = data.get('connection_id')
        tables = data.get('tables', [])

        if not connection_id or len(tables) < 2:
            return JsonResponse({'success': True, 'joins': []})

        connection = get_object_or_404(ExternalConnection, id=connection_id, owner=request.user)
        
        saved_joins_query = ConnectionJoin.objects.filter(connection=connection)
        all_model_joins = [{
            "left_col": f"{j.left_table}.{j.left_column}", 
            "right_col": f"{j.right_table}.{j.right_column}", 
            "type": (j.join_type or "INNER").upper(),
            "left_table": j.left_table,
            "right_table": j.right_table
        } for j in saved_joins_query]

        graph = {}
        for join in all_model_joins:
            left = join["left_table"]
            right = join["right_table"]
            if left not in graph: graph[left] = []
            if right not in graph: graph[right] = []
            graph[left].append(right)
            graph[right].append(left)

        # Check for connectivity
        q = deque([tables[0]])
        visited = {tables[0]}
        while q:
            current = q.popleft()
            for neighbor in graph.get(current, []):
                if neighbor not in visited:
                    visited.add(neighbor)
                    q.append(neighbor)
        
        if not all(t in visited for t in tables):
            return JsonResponse({'success': True, 'joins': []}) # No path exists

        # Build a spanning tree of joins
        joins_to_return = []
        q = deque([tables[0]])
        visited_for_joins = {tables[0]}
        while q:
            current_table = q.popleft()
            for neighbor in graph.get(current_table, []):
                if neighbor in tables and neighbor not in visited_for_joins:
                    visited_for_joins.add(neighbor)
                    q.append(neighbor)
                    
                    join_to_use = next((j for j in all_model_joins if {j['left_table'], j['right_table']} == {current_table, neighbor}), None)
                    if join_to_use:
                        joins_to_return.append(join_to_use)

        final_joins = [{
            'left_col': j['left_col'],
            'right_col': j['right_col'],
            'type': j['type']
        } for j in joins_to_return]

        return JsonResponse({'success': True, 'joins': final_joins})

    except Exception as e:
        logger.error(f"Error finding joins: {e}", exc_info=True)
        return JsonResponse({'success': False, 'error': str(e)}, status=500)


# ================================================================
# HELPER FUNCTIONS
# ================================================================

def report_detail_api(request, report_id):
    """
    Get the full configuration and metadata for a single saved report.
    """
    try:
        report = get_object_or_404(SavedReport, id=report_id, owner=request.user)
        
        return JsonResponse({
            'success': True,
            'id': str(report.id),  # <--- THIS IS THE CRITICAL FIX
            'config': report.report_config,
            'name': report.report_name,
            'description': getattr(report, 'description', ''),
            'permission': 'edit'
        })
    except SavedReport.DoesNotExist:
        return JsonResponse({'success': False, 'error': 'Report not found'}, status=404)
    except Exception as e:
        logger.error(f"Error getting report detail for ID {report_id}: {e}")
        return JsonResponse({'success': False, 'error': str(e)}, status=500)


def get_report_suggestions_api(request, connection_id):
    """
    Provides intelligent report suggestions for a given connection.
    """
    try:
        service = ReportBuilderService()
        suggestions = service.get_report_suggestions(connection_id, request.user)
        return JsonResponse({'success': True, 'suggestions': suggestions})
    except Exception as e:
        logger.error(f"Error generating report suggestions: {e}")
        return JsonResponse({'success': False, 'error': str(e)}, status=500)


@require_POST
def validate_report_config_api(request):
    """
    Validates a report configuration without executing it.
    """
    try:
        report_config = json.loads(request.body)
        service = ReportBuilderService()
        validation = service.validate_report_config(report_config)
        return JsonResponse(validation)
    except json.JSONDecodeError:
        return JsonResponse({'valid': False, 'errors': ['Invalid JSON format.']}, status=400)
    except Exception as e:
        logger.error(f"Error validating report config: {e}")
        return JsonResponse({'valid': False, 'errors': [str(e)]}, status=500)

def _is_numeric_type(column_type):
    """Check if column type is numeric"""
    type_str = str(column_type).lower()
    numeric_types = ['integer', 'bigint', 'smallint', 'decimal', 'numeric', 'real', 'double', 'float']
    return any(num_type in type_str for num_type in numeric_types)

@login_required
@require_POST
def auto_find_joins_api(request):
    """
    Automatically find and suggest joins for the given tables based on common column names.
    This is a simple heuristic and may not find all complex joins.
    """
    try:
        data = json.loads(request.body)
        connection_id = data.get('connection_id')
        tables = data.get('tables', [])
        
        if not connection_id or len(tables) < 2:
            return JsonResponse({'success': True, 'joins': [], 'message': 'Not enough tables to join.'})
            
        engine = get_external_engine(connection_id, request.user)
        if not engine:
            return JsonResponse({'success': False, 'error': 'Database connection failed.'}, status=500)
            
        inspector = inspect(engine)
        suggested_joins = []
        
        # Get columns for each table involved
        table_columns = {}
        for table_name in tables:
            try:
                # Store column names in a set for efficient lookup
                table_columns[table_name] = {col['name'].lower() for col in inspector.get_columns(table_name)}
            except Exception as e:
                logger.warning(f"Could not inspect table {table_name}: {e}")
        
        # Suggest joins based on common column names (a common simple heuristic)
        # This iterates through unique pairs of tables
        for i, table1 in enumerate(tables):
            for table2 in tables[i+1:]:
                if table1 not in table_columns or table2 not in table_columns:
                    continue
                
                # Find the intersection of column names between the two tables
                common_cols = table_columns[table1].intersection(table_columns[table2])
                
                for col in common_cols:
                    # Avoid joining on generic 'id' columns if other options exist, unless it's the only option
                    if len(common_cols) > 1 and col in ['id', 'pk']:
                        continue
                    
                    suggested_joins.append({
                        'left_col': f"{table1}.{col}",
                        'right_col': f"{table2}.{col}",
                        'type': 'INNER',
                    })
                    # Break after finding one common column to avoid multiple joins between the same two tables
                    break
        
        return JsonResponse({
            'success': True,
            'joins': suggested_joins
        })
        
    except Exception as e:
        logger.error(f"Error during auto-join detection: {e}", exc_info=True)
        return JsonResponse({'success': False, 'error': str(e)}, status=500)
    
@login_required
@require_POST
def export_report_csv_api(request):
    """Export report to CSV."""
    try:
        data = json.loads(request.body)
        headers = data.get('headers', [])
        rows = data.get('rows', [])
        
        if not headers or not rows:
            return JsonResponse({'success': False, 'error': 'No data to export'}, status=400)

        response = HttpResponse(content_type='text/csv')
        response['Content-Disposition'] = f'attachment; filename="report_{timezone.now().strftime("%Y%m%d")}.csv"'

        writer = csv.writer(response)
        writer.writerow(headers)
        for row in rows:
            writer.writerow([row.get(h) for h in headers])

        return response
    except Exception as e:
        logger.error(f"Error exporting to CSV: {e}")
        return JsonResponse({'success': False, 'error': str(e)}, status=500)